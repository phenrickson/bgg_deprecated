---
title: "Ad Hoc Analyses for BGG Rating Models"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 3
        keep_md: true
---

```{r global settings, echo=F, warning=F, message=F}

knitr::opts_chunk$set(echo = F,
                      error=F,
                      dev="png",
                      fig.width = 9,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

source("load_packages.R")
source("theme_phil.R")
library(plumber)
rm(a)

```

```{r flextable settings, echo=F, warning=F, message=F}

library(webshot2)
library(flextable)
set_flextable_defaults(theme_fun = theme_alafoli,
                       font.color = "grey10",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

```{r connect to big query}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"

# authorize
bq_auth(email = "phil.henrickson@aebs.com")

# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

# query table
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

# filter
games_info<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_info')

# create caption for plots
my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))

```

We also want to pull down other tables containing the information that we know about games.

```{r query tables with game information}

# game categories
game_categories<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.category_id,
                              b.category
                              FROM bgg.game_categories a
                               LEFT JOIN bgg.category_ids b 
                               ON a.category_id = b.category_id')

# game mechanics
game_mechanics<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.mechanic_id,
                              b.mechanic
                              FROM bgg.game_mechanics a
                               LEFT JOIN bgg.mechanic_ids b 
                               ON a.mechanic_id = b.mechanic_id')

# game publishers
game_publishers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.publisher_id,
                              b.publisher
                              FROM bgg.game_publishers a
                               LEFT JOIN bgg.publisher_ids b 
                               ON a.publisher_id = b.publisher_id')

# game designers
game_designers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.designer_id,
                              b.designer
                              FROM bgg.game_designers a
                               LEFT JOIN bgg.designer_ids b 
                               ON a.designer_id = b.designer_id')

# game artists
game_artists<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.artist_id,
                              b.artist
                              FROM bgg.game_artists a
                               LEFT JOIN bgg.artist_ids b 
                               ON a.artist_id = b.artist_id')

```

## Exploratory Data Analysis

We now will explore how game ratings ratings are a function of the features we have in the dataset. At this stage in the process, we want to restrict ourselves to looking at our training set and to get a basic understanding of both our outcome variable and the features.

We want to analyze both the geek rating and the average rating, so we'll melt our dataset into the structure for analyzing both in one go.

```{r create data for inspection, warning=F, message=F}

# filtering to games with at least 200 user ratings, published after 1900
min_ratings = 200
split_year = 2019

# data set for inspection
data_inspection = active_games %>% 
        filter(usersrated > min_ratings) %>%
        filter(!is.na(name)) %>%
        filter(!is.na(yearpublished)) %>%
        filter(yearpublished <= split_year) %>%
        select(game_id, average, baverage) %>%
        melt(., id.vars = c("game_id")) %>%
        rename(outcome_type = variable,
               outcome = value) %>%
        left_join(., active_games %>%
                          select(-average, -baverage),
                  by = c("game_id"))

```

# Designer Average Weight vs Average Rating

```{r plot mechanics, fig.height=6, fig.width=4}

data_inspection %>%
  left_join(., game_designers,
            by = "game_id") %>%
  group_by(designer_id, designer, outcome_type) %>%
  summarize(median_rating = median(outcome),
         median_weight = median(avgweight),
         n_games = n_distinct(game_id),
         .groups = 'drop') %>%
  filter(n_games > 4) %>%
  ggplot(., aes(x=median_weight,
                size = n_games,
                label =designer,
                y=median_rating))+
  geom_point(alpha=0.6)+
  geom_text(check_overlap=T,
            size =2,
            vjust = 0.5)+
  geom_smooth(method = 'loess',
              formula = 'y~x',
              show.legend =F,
              se=F)+
  theme_phil()+
  theme(legend.title = element_text(),
        legend.text = element_text())+
  my_caption+
  facet_wrap(~outcome_type,
             ncol=1)+
  guides(size = guide_legend(title = "Number of Games",
                                   title.position = 'top'))+
  scale_size_area()+
  xlab("Designer Average Complexity")+
  ylab("Designer Average Rating")+
  scale_size_continuous(breaks=c(1, 10, 50, 100, 200))

```


### Mechanics

We can look at how each type of rating is influenced by mechanics, and we'll see that picture is pretty different for the type of rating. Filtering to mechanics with at least 50 games income and end-game-bonuses are at the top for each, but the average rating tends to skew towards mechanics associated with wargames, whereas the geek rating looks to go towards Euro and social game mechanics.

```{r plot mechanics, fig.height=9, fig.width=10}

min_games = 50

# filter to games with publishers that had at least 300 games
data_inspection %>%
  left_join(., game_mechanics,
            by = "game_id") %>%
  select(timestamp, game_id, name, mechanic_id, mechanic, everything()) %>%
  filter(!is.na(mechanic)) %>%
  #filter(mechanic_id %in% top_mechanics$mechanic_id) %>%
  group_by(mechanic_id, mechanic, outcome_type) %>%
  mutate(median_rating = median(outcome),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > min_games) %>%
  ggplot(., aes(x=reorder_within(x = mechanic, 
                               within = outcome_type,
                               by = median_rating),
                y=outcome))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
        scale_x_reordered()+
        facet_wrap(~outcome_type,
                   scales = "free")+
  coord_flip()+
  theme_phil()+
  geom_boxplot(alpha=0.75,
               outlier.size = 0)+
        xlab("Game Mechanic")+
  ggtitle("Rating by Game Mechanic",
          subtitle = str_wrap(paste("Displaying ratings by mechanic for all games published through", params$end_training_year, "for mechanics with at least", min_games, "games.", sep=" "), 125))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))+
        my_caption

```

#### Publishers

Let's do the same thing for publishers, if only to first illustrate the potential problem with using publishers without some care. If we filter to publishers with at least 100 games, the list tends to be dominated by games we probably don't recognize. Why are CrowdD Games, Asterior Press ,Galapagos Jogos games at the top?

```{r plot publishers, fig.height=10, fig.width=10}

min_games = 50

# rank publishers with min games
top_publishers = data_inspection %>%
  left_join(., game_publishers,
            by = "game_id") %>%
  select(timestamp, game_id, name, publisher_id, publisher, everything()) %>%
  filter(!is.na(publisher)) %>%
  #filter(publisher_id %in% top_publishers$publisher_id) %>%
  group_by(publisher_id, publisher, outcome_type) %>%
  summarize(median_rating = median(outcome),
            n_games = n_distinct(game_id),
            .groups = 'drop') %>%
        group_by(outcome_type) %>%
        filter(n_games > min_games) %>%
        arrange(desc(median_rating)) %>%
        mutate(rank = row_number())

# filter to games with publishers that had at least 300 games
data_inspection %>%
  left_join(., game_publishers,
            by = "game_id") %>%
  select(timestamp, game_id, name, publisher_id, publisher, everything()) %>%
  filter(!is.na(publisher)) %>%
  #filter(publisher_id %in% top_publishers$publisher_id) %>%
  group_by(publisher_id, publisher, outcome_type) %>%
  mutate(median_rating = median(outcome),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > min_games) %>%
        filter(publisher_id %in% top_publishers$publisher_id) %>%
  ggplot(., aes(x=reorder_within(x = publisher, 
                               within = outcome_type,
                               by = median_rating),
                y=outcome))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
        scale_x_reordered()+
        facet_wrap(~outcome_type,
                   scales = "free")+
  coord_flip()+
  theme_phil()+
  geom_boxplot(alpha=0.75,
               outlier.size=0)+
        xlab("Publisher")+
  ggtitle("Rating by Publisher",
          subtitle = str_wrap(paste("Displaying ratings by publisher for all games published through", params$end_training_year, "for publishers with at least", min_games, "games.", sep=" "), 125))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))+
        my_caption

```

After looking into a bit, I realized that a lot of these publishers are foreign language publishers who pick up popular games and then publish them in their language/territory. Presumably, they only do this for very popular games, so these are not the original publisher. In other words, their decision to publish a game is an outcome of games being well-rated and popular, and it shouldn't be used as a predictor.Remember - our goal is to predict games based only on what is known at the time of release. Ideally, we would have data on the original publisher of the game, not those who have picked it up later. Unfortunately, in the BGG database I don't have an easy way of filtering to original publishers. 

How do we counter this? My current solution is to create a whitelist of publishers that I know to be original publishers (so yes, we're relying on some subject matter expertise here) and only include information on these publishers. We could alternatively use mean encoding, but this would lose the direct interpretation of which publishers have positive/negative effects.

```{r look at publishers and create a whitelist, warning=F, message=F}

publisher_list = c(51,
                   1027,
                   21847,
                   10,
                   1001,
                   512,
                   4,
                   140,
                   157,
                   34,
                   28,
                   10001,
                   39,
                   37,
                   20,
                   3,
                   538,
                   52,
                   8923,
                   17,
                   5,
                   3320,
                   597,
                   5400,
                   26,
                   47,
                   11652,
                   19,
                   13,
                   12024,
                   10754,
                   21608,
                   108,
                   221,
                   171,
                   93,
                   25842,
                   140,
                   28072)

#save(publisher_list, file = "publishers_white_list.Rdata")

#load("publishers_white_list.Rdata")

game_publishers %>% 
        select(publisher_id, publisher, game_id) %>%
        right_join(., data_inspection, 
                   by = "game_id") %>%
        group_by(publisher_id, publisher) %>% 
        summarize(games = n_distinct(game_id), 
                  .groups = 'drop') %>% 
        arrange(desc(games)) %>%
        mutate(publisher = abbreviate(publisher, minlength = 30)) %>%
        mutate(publisher_id = as.character(publisher_id)) %>%
        head(200) %>%
        flextable() %>%
        flextable::autofit() %>%
        bg(., i = ~ publisher_id %in% publisher_list,
           bg = 'deepskyblue1') %>%
        set_caption(., caption = "Publishers with most games in training set. Blue indicates that publisher feature is included in feature engineering.")

```

#### Designers and Artists

We can do this same thing for designers, which won't necessarily need to be handled as delicately, though we'll want to set a minimum filter to see the top designers as it will skew towards people who have only published a few games. We'll filter to designers with at least 15 games to start. 

```{r plot designers, warning=F, message=F, fig.height=9, fig.width=10}

min_games = 15

# rank designers with min games
top_designers = data_inspection %>%
  left_join(., game_designers,
            by = "game_id") %>%
  select(timestamp, game_id, name, designer_id, designer, everything()) %>%
  filter(!is.na(designer)) %>%
  #filter(designer_id %in% top_designers$designer_id) %>%
  group_by(designer_id, designer, outcome_type) %>%
  summarize(median_rating = median(outcome),
         n_games = n_distinct(game_id),
         .groups = 'drop') %>%
        group_by(outcome_type) %>%
        filter(n_games > min_games) %>%
        arrange(desc(median_rating)) %>%
        mutate(rank = row_number())

# filter to games with designers
data_inspection %>%
  left_join(., game_designers,
            by = "game_id") %>%
  select(timestamp, game_id, name, designer_id, designer, everything()) %>%
  filter(!is.na(designer)) %>%
  #filter(designer_id %in% top_designers$designer_id) %>%
  group_by(designer_id, designer, outcome_type) %>%
  mutate(median_rating = median(outcome),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > min_games) %>%
        filter(designer_id %in% top_designers$designer_id) %>%
  ggplot(., aes(x=reorder_within(x = designer, 
                               within = outcome_type,
                               by = median_rating),
                y=outcome))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
        scale_x_reordered()+
        facet_wrap(~outcome_type,
                   scales = "free")+
  coord_flip()+
  theme_phil()+
  geom_boxplot(alpha=0.75,
               outlier.size=0)+
        xlab("Designer")+
  ggtitle("Rating by Designer",
          subtitle = str_wrap(paste("Displaying ratings by designer for all games published through", params$end_training_year, "for designers with at least", min_games, "games.", sep=" "), 125))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))+
        my_caption

```

The lists are again pretty different, mainly due to the wargamer crowd. The top designers on the geek rating look to my eye like the ones we would expect to show up - I'll be curious to see how many designers are actually kept in the model given that with 7000 games, most will be tossed out with a near zero variance filter. I'll take a look at this with some more care in my recipe. Another option would be to mean encode instead of hot-encoding - I'll punt on that for now, I think people like seeing the actual effect for designers rather than trying to interpret a mean encoded effect.

I haven't looked at artists too much before, I would expect that these will be heavily correlated with publishers and popular designers.

```{r plot artists, warning=F, message=F, fig.height=9, fig.width=10}

min_games = 15

# rank artists with min games
top_artists = data_inspection %>%
  left_join(., game_artists,
            by = "game_id") %>%
  select(timestamp, game_id, name, artist_id, artist, everything()) %>%
  filter(!is.na(artist)) %>%
  #filter(artist_id %in% top_artists$artist_id) %>%
  group_by(artist_id, artist, outcome_type) %>%
  summarize(median_rating = median(outcome),
         n_games = n_distinct(game_id),
         .groups = 'drop') %>%
        group_by(outcome_type) %>%
        filter(n_games > min_games) %>%
        arrange(desc(median_rating)) %>%
        mutate(rank = row_number())

# filter to games with artists
data_inspection %>%
  left_join(., game_artists,
            by = "game_id") %>%
  select(timestamp, game_id, name, artist_id, artist, everything()) %>%
  filter(!is.na(artist)) %>%
  #filter(artist_id %in% top_artists$artist_id) %>%
  group_by(artist_id, artist, outcome_type) %>%
  mutate(median_rating = median(outcome),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > min_games) %>%
        filter(artist_id %in% top_artists$artist_id) %>%
  ggplot(., aes(x=reorder_within(x = artist, 
                               within = outcome_type,
                               by = median_rating),
                y=outcome))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
        scale_x_reordered()+
        facet_wrap(~outcome_type,
                   scales = "free")+
  coord_flip()+
  theme_phil()+
  geom_boxplot(alpha=0.75,
               outlier.size=0)+
        xlab("Artist")+
  ggtitle("Rating by Artist",
          subtitle = str_wrap(paste("Displaying ratings by artist for all games published through", params$end_training_year, "for artists with at least", min_games, "games.", sep=" "), 125))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))+
        my_caption

```

There are some names up at the top for the geek rating that I recognize, like Chris Quilliams and Ian O'Toole. I'll probably need to go add these guys to the reviewer models now, given that some of the reviewers love specific artists. If anything, the uncredited artist feature will probably be important.


# Visualizations

# TS Data

```{r get ts data}

# query table
games_ts<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.historical_game_rankings')

```


```{r deal with this using a tsibble}

repeat.before = function(x) {   # repeats the last non NA value. Keeps leading NA
    ind = which(!is.na(x))      # get positions of nonmissing values
    if(is.na(x[1]))             # if it begins with a missing, add the 
          ind = c(1,ind)        # first position to the indices
    rep(x[ind], times = diff(   # repeat the values at these indices
       c(ind, length(x) + 1) )) # diffing the indices + length yields how often 
} 

games_tsibble<- games_ts %>%
        filter(!are_duplicated(games_ts, index=date, key=game_id)) %>% # remove duplicates
        filter(game_id %in% games_info$game_id) %>%  # filter to only games that we have active records on
        as_tsibble(index = date,
                   key = game_id) %>%
        tsibble::fill_gaps(., .full=FALSE) %>%
        mutate_at(c("game_release_year", 
                    "bgg_rank",
                    "bgg_average",
                    "bayes_average",
                    "users_rated"),
                 repeat.before) 

```

Example: On Mars

```{r check for on mars}

games_tsibble %>%
        left_join(., games_info,
                  by = "game_id") %>%
        filter(name == 'On Mars') %>%
        filter(date == min(date))

#
games_tsibble %>%
        left_join(., games_info,
                  by = "game_id") %>%
        filter(name == 'On Mars') %>%
        mutate(final_value = case_when(date == max(date) ~ bayes_average,
                                       TRUE ~ NA_real_)) %>%
        ggplot(., aes(x=date, 
                      label = round(final_value,3),
                      y=bayes_average))+
        geom_line()+
        geom_label_repel()+
        theme_phil()+
        facet_wrap(name~.)+
        my_caption

```

Look at geek rating trajectory by release year

```{r releases, fig.height8, fig.width=10}


# games = games_tsibble %>%
#         filter(game_release_year > 2016) %>%
#         select(game_id) %>%
#         unique() %>%
#         sample_n(100) %>%
#         pull(game_id)
# baverage release path
games_tsibble %>%
        filter(game_release_year == 2017 | 
                       game_release_year == 2018 |
                       game_release_year == 2019 |
                       game_release_year == 2020) %>%
        mutate(outcome = 'baverage') %>%
        ggplot(., aes(x=date,
                      y= bayes_average))+
        geom_line(aes(group = game_id),
                  alpha=0.8,
                  color = 'grey60')+
        # geom_smooth(aes(group = game_release_year),
        #             method = 'loess',
        #             se=F,
        #             formula = 'y ~ x')+
        theme_phil()+
        facet_wrap(outcome+game_release_year ~.,
                   ncol =2,
                   scales="free_x")+
        coord_cartesian(ylim = c(4, 9))+
        my_caption+
        ylab("Geek Rating")+
        xlab("Date")

# average release path
games_tsibble %>%
        filter(game_release_year == 2017 | 
                       game_release_year == 2018 |
                       game_release_year == 2019 |
                       game_release_year == 2020) %>%
        mutate(outcome = 'average') %>%
        ggplot(., aes(x=date,
                      y= bayes_average))+
        geom_line(aes(group = game_id),
                  alpha=0.8,
                  color = 'grey60')+
        # geom_smooth(aes(group = game_release_year),
        #             method = 'loess',
        #             se=F,
        #             formula = 'y ~ x')+
        theme_phil()+
        facet_wrap(outcome+game_release_year ~.,
                   ncol =2,
                   scales="free_x")+
        coord_cartesian(ylim = c(4, 9))+
        my_caption+
        ylab("Geek Rating")+
        xlab("Date")

```

```{r unpack, eval=F}

# categories
#categories = 
rename_func(raw_record %>%
                    select(starts_with("cat_")) %>%
                    select_if(~ max(.)>0) %>%
                    names()) %>%
        as_tibble() %>%
        set_names(., c("Categories")) %>%
        flextable() %>%
        flextable::autofit()

# %>%
#         as_raster(., zoom =1, expand=1, webshot = 'webshot')

# mechanics
rename_func(raw_record %>% 
                    select(starts_with("mech_")) %>%
                    select_if(~ max(.)>0) %>%
                    names()) %>%
        as_tibble() %>%
        set_names(., c("Mechanics")) %>%
        flextable() %>%
        flextable::autofit()

# publishers
rename_func(raw_record %>% 
                    select(starts_with("pub_")) %>%
                    select_if(~ max(.)>0) %>%
                    names()) %>%
        as_tibble() %>%
        set_names(., c("Publisher(s)")) %>%
        flextable() %>%
        flextable::autofit()

# artists
rename_func(raw_record %>% 
                    select(starts_with("art_")) %>%
                    select_if(~ max(.)>0) %>%
                    names()) %>%
        as_tibble() %>%
        mutate(value = gsub("Artist ", "", value)) %>%
        set_names(., c("Artist(s)")) %>%
        flextable() %>%
        flextable::autofit()

# designers
rename_func(raw_record %>% 
                    select(starts_with("des_")) %>%
                    select_if(~ max(.)>0) %>%
                    names()) %>%
        as_tibble() %>%
        set_names(., c("Designer(s)")) %>%
        flextable() %>%
        flextable::autofit()

# playingtime
raw_record %>%
        select(minplaytime, maxplaytime) %>%
  unite(playtime, minplaytime:maxplaytime, sep="-") %>%
  mutate(playtime = paste(playtime, "minutes", sep=" ")) %>%
          set_names(., "Playing Time") %>%
        flextable() %>%
        flextable::autofit()

# players
raw_record %>%
        select(minplayers, maxplayers) %>%
        unite(playercount, minplayers:maxplayers, sep="-") %>%
        set_names(., "Player Count") %>%
        flextable() %>%
        flextable::autofit()

# complexity
raw_record %>%
        select(avgweight) %>%
        set_names(., "Complexity") %>%
  mutate_if(is.numeric, round, 2) %>%
        flextable() %>%
        flextable::autofit()

# yearpublished 
raw_record %>%
        select(yearpublished) %>%
        set_names(., "Published") %>%
        mutate_if(is.numeric, as.character) %>%
        flextable() %>%
        flextable::autofit()

```


## Shapley Values for Individual Games

```{r shapley values function}

library(iml)
 
# make my own prediction function
predict.function <- function(model, new_observation) {
  predict(model, new_observation)
}

# X = train_obj %>% as.data.frame()
# y= baked_train$average

# # put ranger into object
# predictor.ranger <- Predictor$new(
#   model = models_down$down_ranger,
#   data = X,
#   y = train_down$NEXT_FOUR_QUARTERS_AT_LEAST_ONE_POLICY,
#   type="prob",
#   class="yes"
#   )
 
# make function for plotting shapley values
shapley_plot<-function(predictor,
                       model_name,
                       train_data,
                       input_id,
                       threshold) {
       
        # require(ModelMetrics)
        # require(gsubfn)
        # require(conflicted)
        # 
    #    conflict_prefer("list", "base")
  
  # use model to define X object with features
  X = train_data %>%
          select(one_of(predictor$data$feature.names)) %>%
          as.data.frame()
  
  # look up game id in training set
  record = train_data %>%
          mutate(.row = row_number()) %>%
          filter(game_id == input_id) %>%
          pull(.row)
 
 # # look up the game
  game_name<-train_data %>%
          mutate(.row = row_number()) %>%
          filter(.row == record) %>%
          pull(name)
  
  # get game id
  id<-train_data %>%
          mutate(.row = row_number()) %>%
          filter(.row == record) %>%
          pull(game_id)
  
  # # temp obj for the predictor
  temp<-predictor
  
  # get shapley values
  shapley <- Shapley$new(temp,
                         sample.size = 200,
                          x.interest = X[record, ])
  
  # actual vs
    average = paste("Average Game Prediction:", round(shapley$y.hat.average, 2))
    actual =  paste("Game Prediction:", round(shapley$y.hat.interest, 2))

    # plot
  plot_shap<-shapley$results %>%
          separate(feature.value, into=c("Feature", "Value"), sep="=") %>%
          mutate(Feature = rename_func(Feature),
                       Value = round(as.numeric(Value), 2)) %>%
          mutate(Feature.Value = paste(Feature, Value, sep="=")) %>%
          filter(abs(phi) > threshold) %>%
          mutate(model = paste(model_name)) %>%
                ggplot(aes(x = reorder(Feature.Value, -phi), y = phi, fill = phi)) +
        geom_hline(yintercept = 0,
               alpha = 0.5)+
                geom_bar(stat = "identity", alpha = 0.95) +
                coord_flip() +
                guides(fill="none")+
                scale_fill_gradient2_tableau(limits=c(-.02,0.02), oob = scales::squish)+
                theme_phil()+
                ggtitle(paste(
                  paste("Game: ", game_name, sep=""),
                  paste("ID: ", id, sep=""), 
                  sep = "\n"),
                        subtitle = paste(average,actual, sep = "\n"))+
                theme(plot.title = element_text(size=12),
                      axis.text.y = element_text(size=8))+
                xlab("")+
                ylab("Feature Contribution to Prediction")+
    facet_wrap(model~.)

  rm(actual, average, temp)

  return(plot_shap)

}

# # put ranger into predictor object
# predictor.ranger <- Predictor$new(
#   model = ranger_fit,
#   data = X,
#   y = y
#   )

ranger_average= ratings_models %>% 
                  filter(outcome_type =='average' ) %>%
        select(ranger_fit) %>%
        mutate(fit = map(ranger_fit, ~ extract_fit_parsnip(.x))) %$% fit[[1]]

ranger_baverage= ratings_models %>% 
                  filter(outcome_type =='baverage' ) %>%
        select(ranger_fit) %>%
        mutate(fit = map(ranger_fit, ~ extract_fit_parsnip(.x))) %$% fit[[1]]

ranger_x = baked_train %>%
        select(one_of(names(ranger_average$fit$variable.importance))) %>%
        as.data.frame()

# ranger for average
predictor.ranger.average = Predictor$new(
          model = ranger_average,
          data = ranger_x,
          y = baked_train$average)

# ranger for average
predictor.ranger.baverage = Predictor$new(
          model = ranger_baverage,
          data = ranger_x,
          y = baked_train$baverage)

rai

# xgbTree
xgbTree_average= ratings_models %>% 
                  filter(outcome_type =='average' ) %>%
        select(xgbTree_fit) %>%
        mutate(fit = map(xgbTree_fit, ~ extract_fit_parsnip(.x))) %$% fit[[1]]

xgbTree_baverage= ratings_models %>% 
                  filter(outcome_type =='baverage' ) %>%
        select(xgbTree_fit) %>%
        mutate(fit = map(xgbTree_fit, ~ extract_fit_parsnip(.x))) %$% fit[[1]]

xgbTree_x = baked_train %>%
        select(one_of(xgbTree_average$fit$feature_names)) %>%
        as.data.frame()

# xgbTree for average
predictor.xgbTree.average = Predictor$new(
          model = xgbTree_average,
          data = xgbTree_x,
          y = baked_train$average)

# xgbTree for average
predictor.xgbTree.baverage = Predictor$new(
          model = xgbTree_baverage,
          data = xgbTree_x,
          y = baked_train$baverage)

```

# Get Games

```{r pull games}

source("functions/get_models_and_training_data.R")

bar= get_models_and_training_data()
```

Plot

```{r }

```

