---
title: "Predicting Geek Ratings"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: true
---

This notebook is for building predictive models of boardgame ratings.

```{r global seetings, echo=F, warning=F, message=F}

knitr::opts_chunk$set(echo = F,
                      dev="png",
                      fig.width = 8,
                      fig.height = 8)

options(knitr.duplicate.label = "allow")

options(scipen=999)

```

```{r load and set packages, warning=F, message=F, include=FALSE, results = 'hide'}

source("load_packages.R")
source("theme_phil.R")

```

## Get Data from Big Query

### Active Game Rankings

We'll first connect to the most recent day of BGG data that we have in our database. These are the active rankings of games - where they stand in the BGG database as of the most recent load, which I usually update once a week.

```{r connect to big query}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"


# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

```


```{r query active games}

# query table
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

```

### Additional Game Information

We also want to pull down other tables containing the information that we know about games.

```{r query tables with game information}

# general game info
games_info<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_info')

# game categories
game_categories<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.category_id,
                              b.category
                              FROM bgg.game_categories a
                               LEFT JOIN bgg.category_ids b 
                               ON a.category_id = b.category_id')

# game mechanics
game_mechanics<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.mechanic_id,
                              b.mechanic
                              FROM bgg.game_mechanics a
                               LEFT JOIN bgg.mechanic_ids b 
                               ON a.mechanic_id = b.mechanic_id')

# game publishers
game_publishers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.publisher_id,
                              b.publisher
                              FROM bgg.game_publishers a
                               LEFT JOIN bgg.publisher_ids b 
                               ON a.publisher_id = b.publisher_id')

# game designers
game_designers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.designer_id,
                              b.designer
                              FROM bgg.game_designers a
                               LEFT JOIN bgg.designer_ids b 
                               ON a.designer_id = b.designer_id')

# # game artists
# game_artists<-DBI::dbGetQuery(bigquerycon, 
#                               'SELECT 
#                               a.game_id,
#                               b.artist_id,
#                               b.artist
#                               FROM bgg.game_artists a
#                                LEFT JOIN bgg.artist_ids b 
#                                ON a.artist_id = b.artist_id')


```

## Exploratory Analysis

We now will explore how game ratings ratings are a function of the features we have in the dataset. At this stage in the process, we want to restrict ourselves to looking at our training set and to get a basic understanding of both our outcome variable and the features.

#### Year Published

The minimum year published in our dataset is -3000, which are games like Marbles and Backgammon. If we filter to games from 1950 to 2022, we can see the rise in the geek rating of newer games.

```{r plot game ratings vs year published, warning=F}

#library(plotly)
# filter to games publisehd after 19gg50
#ggplotly(

active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  ggplot(., aes(x=yearpublished, 
                label = name,
                y=baverage,
                size =usersrated))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  theme(legend.title = element_text())+
  guides(size = guide_legend(title = "Users Rated",
                             title.position = "top"),
         color = "none")+
  xlab("Year Published")+
  ylab("Geek Rating")

```

#### Weight, Playing Time, and Min/Max Players

We know that there's a strong correlation between the complexity of a game and its geek rating, as the BGG community tends to buy and like heavier games.

```{r plot these other two, warning=F, message=F}

# hist
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  ggplot(., aes(x=avgweight))+
  geom_density(fill = 'grey20',
               alpha=0.8,
               color = NA)+
  theme_phil()+
  xlab("Average Weight")

# plot vs bgg rating
# scatter
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  ggplot(., aes(x=avgweight, 
                label = name,
                y=baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  ylab("Geek Rating")+
  xlab("Average Weight")

```

Playing time is an interesting feature of a game that I would expect to have a nonlinear relationship with the geek rating. 

```{r plot playing time, warning=F, message=F}

# summary
summary(active_games$playingtime)

# which are the longest games?
active_games %>% 
  arrange(desc(playingtime)) %>%
  select(game_id, name, playingtime, avgweight, baverage) %>%
  mutate_if(is.numeric, round, 3) %>%
  head(100) %>%
  flextable() %>%
  autofit()

# hist
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  ggplot(., aes(x=log(playingtime)))+
  geom_density(fill = 'grey20',
               alpha=0.8,
               color = NA)+
  theme_phil()+
  xlab("Playing Time in Logged Minutes")+
  geom_vline(xintercept = log(c(15, 60, 120, 360)),
             linetype = 'dotted')+
  labs(caption = "Lines at 15, 60, 120, and 360, respectively")

# plot vs bgg rating
# scatter
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  mutate(playingtime = log1p(playingtime)) %>%
  ggplot(., aes(x=playingtime,
                label = name,
                y=baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  ylab("Geek Rating")+
  xlab("Playing Time in Minutes (logged)")+
  geom_vline(xintercept = log1p(c(15, 60, 120, 360)),
             linetype = 'dotted')+
  geom_smooth()+
  labs(caption = "Lines at 15, 60, 120, and 360, respectively")


# plot vs bgg rating
# scatter
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2022) %>%
  filter(playingtime > 0 & playingtime < 600) %>%
  ggplot(., aes(x=playingtime,
                label = name,
                y=baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  ylab("Geek Rating")+
  xlab("Playing Time in Minutes")+
  geom_smooth()


```
Min and max players

```{r now look at min and max players}

# scatter min players
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2021) %>%
  ggplot(., aes(x=minplayers,
                y = baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth()+
  xlab("Minimum Players")+
  ylab("Geek Rating")

# scatter min players
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2021) %>%
  ggplot(., aes(x=log1p(minplayers),
                y = baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth()+
  xlab("Minimum Players (logged)")+
  ylab("Geek Rating")


# scatter max players
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2021) %>%
  ggplot(., aes(x=maxplayers,
                y = baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth()+
  xlab("Maximum Players")+
  ylab("Geek Rating")

# what are theese games with a ton of players
active_games %>% 
  arrange(desc(maxplayers)) %>%
  select(game_id, name, minplayers, maxplayers, avgweight, baverage) %>%
  mutate_if(is.numeric, round, 3) %>%
  head(100) %>%
  flextable() %>%
  autofit()
  
# 
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2021) %>%
  ggplot(., aes(x=log1p(maxplayers),
                y = baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth()+
  xlab("Maximum Players (logged)")+
  ylab("Geek Rating")

# 
active_games %>% 
  filter(yearpublished > 1950) %>%
  filter(yearpublished < 2021) %>%
  mutate(maxplayers_trunc = case_when(maxplayers >= 12 ~ 12,
                   TRUE ~ maxplayers)) %>%
  arrange(desc(maxplayers_trunc)) %>%
  ggplot(., aes(x=maxplayers_trunc,
                y = baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth()+
  xlab("Maximum Players Truncated")+
  ylab("Geek Rating")

```

What about playing time per player?

```{r playing time per player, warning=F, message=F}

# distribution
active_games %>%
  select(game_id, name, baverage, playingtime, minplaytime, maxplaytime, minplayers, maxplayers) %>%
  arrange(game_id) %>%
  mutate(minplayers = case_when(minplayers == 0 ~ 1,
                                TRUE ~ minplayers)) %>%
  mutate(maxplayers = case_when(maxplayers == 0 ~ minplayers,
                                TRUE ~ maxplayers)) %>%
  mutate(time_per_player = maxplaytime / maxplayers) %>%
  ggplot(., aes(x=log1p(time_per_player)))+
  geom_density(fill = 'grey20',
               color =NA,
               alpha=0.8)+
  theme_phil()+
  xlab("Time Per Player (logged)")

# scatter
active_games %>%
  select(game_id, name, baverage, playingtime, minplaytime, maxplaytime, minplayers, maxplayers) %>%
  arrange(game_id) %>%
  mutate(minplayers = case_when(minplayers == 0 ~ 1,
                                TRUE ~ minplayers)) %>%
  mutate(maxplayers = case_when(maxplayers == 0 ~ minplayers,
                                TRUE ~ maxplayers)) %>%
  mutate(time_per_player = maxplaytime / maxplayers) %>%
  ggplot(., aes(x=log1p(time_per_player),
                y=baverage))+
  geom_jitter(alpha=0.5)+
  theme_phil()+
  geom_smooth(method = 'loess', formula = 'y ~ x')+
  xlab("Playing Time per Player (logged)")+
  ylab("Geek Rating")

```

#### Game Ratings by Category

```{r explore ratings by category, fig.height=4}

# filter to games with publishers that had at least 300 games
# jitter plot
active_games %>%
  filter(yearpublished < 2022) %>%
  left_join(., game_categories,
            by = "game_id") %>%
  select(timestamp, game_id, name, category_id, category, everything()) %>%
  filter(!is.na(category)) %>%
  #filter(category_id %in% top_categorys$category_id) %>%
  filter(yearpublished<2021) %>%
  group_by(category_id) %>%
  mutate(median_rating = median(baverage),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > 200) %>%
  ggplot(., aes(x=reorder(category, 
                          median_rating),
                y=baverage))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
  coord_flip(ylim = c(4, 8.5))+
  theme_phil()+
  geom_boxplot(alpha=0.75)+
  xlab("Game Category")+
  ylab("Geek Rating")+
  ggtitle("Geek Rating by Game Category",
          subtitle = str_wrap("Displaying Geek Ratings for all games published prior to 2022 for categories with at least 200 games. Points jittered to improve visibility.", 125))+
  labs(caption=paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))

```

#### Game Ratings by Mechanic

Look at ratings by mechanic.

```{r table of top mechanics}

top_mechanics<-active_games %>%
  filter(yearpublished<2022) %>%
  left_join(., game_mechanics,
            by = "game_id") %>%
  select(timestamp, game_id, name, mechanic_id, mechanic, everything()) %>%
  filter(!is.na(mechanic)) %>%
  group_by(mechanic_id, mechanic) %>%
  summarize(games = n_distinct(game_id),
            median_rating = median(baverage, na.rm=T),
            sd_rating = sd(baverage, na.rm=T),
            .groups = 'drop') %>%
  ungroup() %>%
  filter(games > 10) %>%
  arrange(desc(median_rating)) %>%
  arrange(desc(games))

top_mechanics %>%
    mutate_if(is.numeric, round ,2) %>%
    rename(`Mechanic ID` = mechanic_id,
         `Mechanic` = mechanic,
         `# Games` = games,
         `Median Rating` = median_rating,
         `SD Rating` = sd_rating) %>%
  arrange(desc(`Median Rating`)) %>%
  DT::datatable()

rm(top_mechanics)
  
```

Plot the distribution by mechanic, filtering to games with only a set number.

```{r plot by mechanics, fig.height=4}

# filter to games with publishers that had at least 300 games
active_games %>%
  left_join(., game_mechanics,
            by = "game_id") %>%
  select(timestamp, game_id, name, mechanic_id, mechanic, everything()) %>%
  filter(!is.na(mechanic)) %>%
  #filter(mechanic_id %in% top_mechanics$mechanic_id) %>%
  filter(yearpublished<2022) %>%
  group_by(mechanic_id) %>%
  mutate(median_rating = median(baverage),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > 200) %>%
  ggplot(., aes(x=reorder(mechanic, 
                          median_rating),
                y=baverage))+
  geom_jitter(width=0.2,
              height=0,
              alpha=0.25)+
  coord_flip(ylim = c(4, 8.5))+
  theme_phil()+
  geom_boxplot(alpha=0.75)+
  xlab("Game Mechanic")+
  ylab("Geek Rating")+
  ggtitle("Geek Rating by Game Mechanic",
          subtitle = str_wrap("Displaying Geek Ratings for all games published prior to 2022 for mechanics with at least 200 games", 125))+
  labs(caption=paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=8))



```
```{r designer ratings table}

top_designers<-active_games %>%
  filter(yearpublished<2021) %>%
  left_join(., game_designers,
            by = "game_id") %>%
  select(timestamp, game_id, name, designer_id, designer, everything()) %>%
  mutate(designer = gsub("\\)", "", gsub("\\(", "", designer))) %>%
  filter(!is.na(designer)) %>%
  group_by(designer_id, designer) %>%
  summarize(games = n_distinct(game_id),
            median_rating = median(baverage, na.rm=T),
            sd_rating = sd(baverage, na.rm=T),
            .groups = 'drop') %>%
  ungroup() %>%
  arrange(desc(median_rating)) %>%
  filter(games > 5) %>%
  arrange(desc(median_rating)) %>%
  mutate_if(is.numeric, round, 3)

top_designers %>%
  rename(`Designer ID` = designer_id,
         `Designer` = designer,
         `Published Games` = games,
         `Median Rating` = median_rating,
         `SD Rating` = sd_rating) %>%
  DT::datatable()

```

We can visualize each designer's distribution of games.

```{r visualize designer games, fig.height=4}

active_games %>%
  left_join(., game_designers,
            by = "game_id") %>%
  select(timestamp, game_id, name, designer_id, designer, everything()) %>%
  filter(!is.na(designer)) %>%
  #filter(designer_id %in% top_designers$designer_id) %>%
  filter(yearpublished<2021) %>%
  group_by(designer_id) %>%
  mutate(median_rating = median(baverage),
         n_games = n_distinct(game_id)) %>%
  ungroup() %>%
  filter(n_games > 25) %>%
  ggplot(., aes(x=reorder(designer, 
                          median_rating),
                y=baverage))+
  geom_point(alpha=0.25)+
  # geom_jitter(width=0.15,
  #             height=0,
  #             alpha=0.25)+
  coord_flip(ylim = c(4, 8.5))+
  theme_phil()+
  geom_boxplot(alpha=0.75)+
  xlab("Game Designer")+
  ylab("Geek Rating")+
  ggtitle("Geek Rating by Game Designer",
          subtitle = str_wrap("Displaying Geek Ratings for all games published prior to 2021 for game designers with at least 25 games", 125))+
  labs(caption=paste("Data from boardgamegeek.com as of", max(as.Date(active_games$timestamp))))+
  theme(plot.title = element_text(size=12),
        plot.subtitle =  element_text(size=10),
        axis.text.y = element_text(size=6))

rm(top_designers)

```


## Predictive Modeling

Let's now turn to the task of predictive modeling.

Our outcome is the geek rating, which is a function of the games average + the number of user ratings.


```{r plot games and user ratings, warning=F, message=F}

active_games %>%
              filter(yearpublished < 2022) %>%
              mutate(min_user_ratings = 100) %>%
              nest(-min_user_ratings) %>%
  bind_rows(.,
            active_games %>%
              filter(yearpublished < 2022) %>%
              mutate(min_user_ratings = 250) %>%
              nest(-min_user_ratings)) %>%
    bind_rows(.,
            active_games %>%
              filter(yearpublished < 2022) %>%
              mutate(min_user_ratings = 1000) %>%
              nest(-min_user_ratings)) %>%
  unnest() %>%
  filter(usersrated < min_user_ratings) %>%
  select(min_user_ratings, usersrated, baverage) %>%
  mutate(min_user_ratings = factor(min_user_ratings)) %>%
  melt(id.vars=c("min_user_ratings")) %>%
  ggplot(., aes(x=value,
                fill = min_user_ratings,
                color = min_user_ratings)) +
  geom_density(alpha=0.8)+
  facet_wrap(variable~.,
             scales="free",
             ncol =1)+
  theme_phil()+
  scale_fill_viridis_d()+
  scale_color_viridis_d()


```

### Create Game Dataset

```{r pivot and join}

min_users = 200

# combine all
games_train<-active_games %>%
  select(timestamp, game_id, name, average, baverage, usersrated) %>%
  filter(usersrated > min_users) %>%
  left_join(., games_info %>% # join game info
              select(game_id, yearpublished, avgweight, minage, minplayers, maxplayers, playingtime),
            by = c("game_id")) %>%
  filter(yearpublished < 2022) %>% # use games prior to 2022 as our training set
  left_join(., game_categories %>% # join categories
              mutate(category = gsub("\\)", "", gsub("\\(", "", category))) %>%
              mutate(category = tolower(paste("cat", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", category))), sep="_"))) %>%
              mutate(has_category = 1) %>%
              select(-category_id) %>%
              pivot_wider(names_from = c("category"),
                          values_from = c("has_category"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
  left_join(., game_mechanics %>% # join mechanics
              mutate(mechanic = tolower(paste("mech", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", mechanic))), sep="_"))) %>%
              mutate(has_mechanic = 1) %>%
              select(-mechanic_id) %>%
              pivot_wider(names_from = c("mechanic"),
                          values_from = c("has_mechanic"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
      left_join(., game_designers %>% # join designers
              mutate(designer = gsub("\\)", "", gsub("\\(", "", designer))) %>%
              mutate(designer = tolower(paste("des", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", designer))), sep="_"))) %>%
              mutate(has_designer = 1) %>%
              select(-designer_id) %>%
              pivot_wider(names_from = c("designer"),
                          values_from = c("has_designer"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) 

```

###  Predicting Geek Rating

We'll create a recipe for our baseline model, which only uses observable game info such as playing time, player counts, complexity (more on this later), and categories + mechanics.

A couple of things to note here. We're going to filter to games published since 1950, as well as filter to games with a set number of user ratings.

```{r create a recipe for the geek rating}

recipe_baverage<- recipe(baverage~., x = games_train) %>%
  update_role(timestamp,
        usersrated,
        game_id,
        name,
        average,
        new_role = "id") %>%
  step_filter(!is.na(yearpublished)) %>%
  step_filter(
      cat_collectible_components !=1 &
      cat_expansion_for_basegame != 1) %>% # remove specific categories that count expansions
 # step_filter(yearpublished > 1950) %>%
  step_mutate(yearpublished = case_when(yearpublished <= 1900 ~ 1900,
                                         TRUE ~ as.numeric(yearpublished))) %>% # truncate yearpublished
 # step_mutate(years_since_published = as.numeric(year(Sys.Date()))-yearpublished) %>%
  step_impute_median(avgweight,
                    minplayers,
                    maxplayers,
                    playingtime,
                    minage) %>% # medianimpute numeric predictors
  step_mutate(minplayers = case_when(minplayers < 1 ~ 1,
                                     minplayers > 10 ~ 10,
                                     TRUE ~ minplayers),
              maxplayers = case_when(maxplayers < 1 ~ minplayers,
                                     maxplayers > 20 ~ 20,
                                     TRUE ~ maxplayers)) %>% # truncate player range
  step_mutate(time_per_player = playingtime/ maxplayers) %>% # make time per player variable
  step_mutate_at(starts_with("cat_"),
           fn = ~ replace_na(., 0)) %>%
  step_mutate_at(starts_with("mech_"),
           fn = ~ replace_na(., 0)) %>%
  step_mutate_at(starts_with("des_"),
           fn = ~ replace_na(., 0)) %>%
  step_mutate(number_mechanics = rowSums(across(starts_with("mech_"))),
              number_categories = rowSums(across(starts_with("cat_"))),
              number_designers = rowSums(across(starts_with("des_")))) %>%
  step_log(playingtime,
     time_per_player,
     offset = 1) %>%
  step_zv(all_predictors()) %>%
  step_nzv(all_predictors(),
     freq_cut = 150/1) %>%
  check_missing(all_numeric_predictors())

# normalize
recipe_norm_baverage<-recipe_baverage %>%
  step_normalize(all_predictors())

# summary of recipe
summary(recipe_baverage)

```

#### Baseline Error Rate

Before we get into modeling, let's establish up front the baseline accuracy of a null model. If we were to simply predict the mean for every game, how well would we do?

```{r establish baseline, warning=F}

# specify regression metrics
reg_metrics<-metric_set(yardstick::rmse,
                        yardstick::rsq,
                        yardstick::mae,
                        yardstick::mape)

#  get performance of baseline
null_results<-games_train %>%
  select(baverage) %>%
  mutate(pred = mean(baverage)) %>%
  reg_metrics(truth = baverage,
              estimate = pred) %>%
  filter(!is.na(.estimate)) %>%
  mutate_if(is.numeric, round, 3) %>%
  mutate(model = "null") %>%
  select(model, everything())

null_results

```

#### Worfklow with tidymodels

Now that we have our recipe in place, we can proceed to building a modeling workflow. We'll set up cross validation on our training set for tuning models which rely on tuning parameters.

```{r set up validation set, warning=F, message=F}
library(rsample)

set.seed(234)
train_folds<-vfold_cv(games_train, 
                      strata = baverage,
                      v = 5,
                      repeats = 1)

```

Now we'll set up the models we plan to use, which to start will be a penalized logit, a logistic regression fit with Stan, and gradient boosted trees.

```{r specify models}

library(tidymodels)
library(workflows)

# simple linear regression
lm_mod <- 
  linear_reg() %>% 
  set_engine("lm")

# stan linear regression
set.seed(123)
prior_dist <- rstanarm::student_t(df = 1)

stan_lm_mod <-   
  linear_reg() %>% 
  set_engine("stan", 
             prior_intercept = prior_dist, 
             prior = prior_dist,
             iter = 6000)

# penalized linear regression
glmnet_mod<- 
  linear_reg(penalty = tune::tune(),
             mixture = 0.5) %>%
  set_engine("glmnet")

```

##### Penalized Regression

Now build the workflow and train the model.

```{r set up workflow}

# specify grid for tuning
glmnet_grid <- tibble(penalty = 10^seq(-4, -1, 
                                       length.out = 30))

# build workflow
set.seed(1999)
glmnet_workflow<-
  workflow() %>% 
  add_model(glmnet_mod) %>% 
  add_recipe(recipe_norm_baverage %>%
               step_normalize(all_predictors()))

# tune
glmnet_results <-
  glmnet_workflow %>%
  tune_grid(train_folds,
            grid = glmnet_grid,
            control = control_grid(save_pred = TRUE),
            metrics = reg_metrics) %>%
  mutate(model = "glmnet")

```

Let's look at the results across the tuning range.

```{r show tuning range for glmnet}

# plot
glmnet_results %>%
  collect_metrics() %>%
  ggplot(., aes(x=penalty,
                y=mean))+
  geom_line()+
  facet_wrap(model~.metric,
             scales="free_y")+
  theme_phil()

```

We can plot the predicted vs actual.

```{r plot predictions glmnet}
 
# grab the best tuning results
glmnet_best<-glmnet_results %>%
  select_best("rmse")

# what were our best results
glmnet_results %>% 
  collect_metrics() %>%
  filter(penalty == glmnet_best$penalty) %>%
  mutate_if(is.numeric, round, 3) %>%
  select(model, .metric, mean, std_err)
  
# grab the predictions and plot
glmnet_results %>%
  collect_predictions(parameters = glmnet_best) %>%
  mutate(model = "glmnet") %>%
  ggplot(., aes(x=.pred,
                y=baverage))+
  geom_point(alpha=0.5)+
  facet_wrap(model~.)+
  theme_phil()+
  geom_smooth(formula = y ~ x, method = "loess")+
  coord_cartesian(xlim = c(3.5, 9),
                  ylim = c(3.5, 9))+
  stat_cor(label.x = 3.5,
           p.accuracy = 0.001)+
  geom_abline(slope =1,
              intercept = 0,
              col = "grey60",
              linetype = 'dashed')

```
And a residual plot.

```{r residual plot from glmnet}

glmnet_results %>%
  collect_predictions(parameters = glmnet_best) %>%
  mutate(model = "glmnet") %>%
  select(id, .row, baverage, .pred, penalty, model) %>%
  mutate(.resid = baverage - .pred) %>%
  ggplot(., aes(x=.pred, 
                y= .resid))+
  geom_point(alpha=0.5)+
  theme_phil()+
  facet_wrap(model~.)
  
```

I'm interested in plot to see how the predictions compare to the actual in terms of their rank. It's less important that we get the magnitude right than that we get the ranking.

```{r percentile percentile plot, warning=F, message=F}

glmnet_results %>%
  collect_predictions(parameters = glmnet_best) %>%
  mutate(model = "glmnet") %>%
  select(id, .row, baverage, .pred, penalty, model) %>%
  melt(id.vars = c("id", ".row", "penalty", "model")) %>%
  group_by(variable) %>%
  summarise(quantile = seq(0, 1, 0.025),
            value = quantile(value, seq(0, 1, 0.025)),
            .groups = 'drop') %>%
  ggplot(., aes(x=quantile,
                y=value,
                colour = variable))+
  geom_point()+
  theme_phil()+
  scale_color_manual(values = c("deepskyblue1", "navy"))

glmnet_results %>%
  collect_predictions(parameters = glmnet_best) %>%
  sample_n(500) %>%
  mutate(model = "glmnet") %>%
  select(id, .row, baverage, .pred, penalty, model) %>%
  arrange(baverage) %>%
  mutate(rank = row_number()) %>%
  melt(id.vars = c("id", ".row", "penalty", "model", "rank")) %>%
  ggplot(., aes(x=rank,
                y = value,
                color = variable))+
  geom_point(alpha=0.75)+
  theme_phil()+
  scale_color_manual(values = c("deepskyblue1", "navy"))+
  facet_wrap(model~.)+
  ylab("Rating")+
  xlab("Rank")

```
Let's take a look at the individual predictions.

```{r get predictions from glmnet, warning=F, message=F}

# baked data
baked_train<- recipe_baverage %>%
  prep(games_train, strings_as_factor = F) %>%
  bake(games_train) %>%
  mutate(.row = row_number())

# set color functions
col_func<- function(x) {
  
  breaks<-quantile(x, probs = seq(0, 1, by=.1), na.rm=T) %>% as.vector()
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

set.seed(1999)
samp<-baked_train %>%
  mutate(strata = plyr::round_any(baverage, .5)) %>%
  select(game_id, strata) %>%
  group_by(strata) %>%
  filter(strata > 5 & strata <8.5) %>%
  sample_n(size=8) %>%
  pull(game_id)

# get predictions
glmnet_results %>%
  collect_predictions(parameters = glmnet_best) %>%
  left_join(., baked_train) %>%
  arrange(.row) %>%
  select(id, .pred, .row, baverage, game_id, name) %>%
  filter(game_id %in% samp) %>%
  arrange(desc(.pred)) %>%
  mutate(game_id = as.character(game_id)) %>%
  mutate(model = "glmnet") %>%
  select(model, game_id, name, baverage, .pred) %>%
  arrange(desc(baverage)) %>%
  mutate_if(is.numeric, round, 3) %>%
  flextable() %>%
  autofit() %>%
        bg(j = c('.pred', 'baverage'),
           bg = col_func)


  # ggplot(., aes(x=.pred,
  #               label = name,
  #               y= baverage))+
  # geom_point()+
  # geom_label_repel(max.overlaps=10,
  #                  size = 2.5)+
  # theme_phil()+
  # geom_abline(slope =1,
  #        intercept=0,
  #        linetype = 'dashed')

glmnet_fit<-glmnet_workflow %>%
  finalize_workflow(glmnet_best) %>%
  fit(games_train)

glmnet_coefs<-glmnet_fit %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(term != '(Intercept)')

```

The model completely whiffs on Crokinole! I'm not really surprised, given that it has very few things that the model really likes such as complexity, mechanics, as well as recency, which we can see when we unpack the coefficients from the model.

```{r show the damn coef plots, fig.height=4}

glmnet_coefs<-glmnet_workflow %>%
  finalize_workflow(glmnet_best) %>%
  fit(games_train) %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(term != '(Intercept)')


rename_func<-function(x) {
  
  x<-gsub("cat_memory", "cat_memory_game", x)
  x<-gsub("cat_","", x)
  x<-gsub("mech_","", x)
  x<-gsub("pub_","", x)
  x<-gsub("des_","", x)
  x<-gsub("avgweight", "Average Weight", x)
  x<-gsub("yearpublished", "Year Published", x)
  x<-gsub("minage", "Min Age", x)
  x<-gsub("playingtime", "Playing Time", x)
  x<-gsub("maxplayers", "Max Players", x)
  x<-gsub("minplayers", "Min Players", x)
  x<-gsub("_", " ", x)

  str_to_title(x)

}

# now make coef plot
glmnet_coefs %>%
  filter(abs(estimate) > .01) %>%
  mutate(term = rename_func(term)) %>%
  ggplot(., aes(x = reorder(term, estimate),
                y=estimate))+
  coord_flip()+
  geom_point()+
  theme_phil()+
  geom_hline(yintercept = 0)+
  xlab("predictor")+
  theme(axis.text.y = element_text(size=6))
                
```

##### Linear Regression with STAN

Let's now fit our a linear model using stan. We'll fit to our training folds in order to estimate our out of sample error - this is slightly computationally taxing and we could do better to use the loo package to estimate the model's performance, but we'll use the training folds to directly compare to our other models.

```{r fit bayesian lienar regression}

# build workflow
set.seed(1999)
stan_lm_workflow<-
  workflow() %>% 
  add_model(stan_lm_mod) %>% 
  add_recipe(recipe_norm_baverage)

# fit
stan_lm_results <-stan_lm_workflow %>%
  fit_resamples(train_folds,
            control = control_grid(save_pred = TRUE),
            metrics = reg_metrics)

```

We can look at the predictions from our model.

```{r get preds from stan, warning=F, message=F}

# get the resampling results
stan_lm_results %>%
  collect_metrics()

stan_lm_results %>%
  collect_predictions() %>%
  arrange(.row) %>%
  left_join(., baked_train) %>%
  arrange(desc(.pred)) %>%
  ggplot(., aes(x=.pred, y=baverage))+
  geom_point(alpha=0.25)+
    geom_smooth(formula = y ~ x, method = "loess")+
  coord_cartesian(xlim = c(3.5, 9),
                  ylim = c(3.5, 9))+
  stat_cor(label.x = 3.5,
           p.accuracy = 0.001)+
  geom_abline(slope =1,
              intercept = 0,
              col = "grey60",
              linetype = 'dashed')+
  theme_phil()

```

The biggest utility of using Stan to train our linear model is that we can easily simulate from it to display the uncertainty around our parameter estimates, as well as the uncertainty around our predictions. For this we'll grab the full model.

```{r predict folds, echo=F, warning=F}

set.seed(1999)
stan_fit<-stan_lm_workflow %>%
  fit(games_train) %>%
  extract_fit_parsnip()

```

We can plot the coefficients from this model along with their confidence interval.

```{r get model fit from stan, warning=F, message=F, fig.height=4}

library(tidybayes)
library(broom.mixed)

stan_fit %>%
  tidy(conf.int=T) %>% 
  arrange(desc(estimate)) %>%
  filter(term != '(Intercept)') %>%
  mutate(term = rename_func(term)) %>%
  ggplot(., aes(x=reorder(term,
                          estimate),
                y=estimate,
                ymin = conf.low,
                ymax = conf.high))+
  geom_pointrange(size = 0.1)+
  coord_flip()+
  geom_hline(yintercept = 0)+
  ylab("Estimate")+
  xlab("")+
  theme_phil()+
  theme(axis.text.y = element_text(size = 5))+
  theme(panel.grid.major = element_blank())
  
```

We can also get the predictive interval for each individual predictions, sampling from the posterior.

```{r get predictive interval from stan model, fig.height=4}

set.seed(1999)
baked_train_norm <-recipe_norm_baverage %>%
  prep(games_train) %>%
  bake(games_train) %>%
  mutate(.row = row_number())

# posterior predict
pred<-stan_fit$fit %>%
  posterior_predict(baked_train_norm)

# temp_dat
temp_dat<-pred %>%
  tidy_draws() %>%
  melt(id.vars = c(".chain",
                   ".iteration",
                   ".draw")) %>%
  mutate(.row = as.integer(variable)) %>%
  left_join(., baked_train_norm %>%
              select(game_id, name, baverage, .row)) %>%
  filter(game_id %in% samp)
  
# plot each simulation
temp_dat %>%
  ggplot(., aes(x=reorder(name,
                         baverage),
                y=value)) +
#  geom_density_ridges()+
  geom_point(alpha=0.05,
             col = "grey60",
             size=0.8)+
  coord_flip() +
  theme_phil()+
  geom_point(data = temp_dat,
             aes(x=reorder(name,
                           baverage),
                 y=baverage),
             col = "blue")+
  ylab("Simulated Ratings from Model")+
  xlab("")

# get just the predictive interval
t(apply(pred, 2, quantile, probs = c(.05, .1, .9, .95))) %>%
  as_tibble() %>%
  mutate(.row = row_number()) %>%
  left_join(., baked_train_norm %>%
              select(game_id, name, baverage, .row)) %>%
  filter(game_id %in% samp) %>%
  ggplot(., aes(x=reorder(name,
                         baverage),
               y=baverage,
                ymin = `5%`,
               ymax = `95%`)) +
  geom_pointrange()+
#  geom_density_ridges()+
  geom_point(alpha=0.05,
             col = "grey60",
             size=0.8)+
  coord_flip() +
  theme_phil()

rm(temp_dat, pred, stan_pred)


```

We can plot simulated datsets from our model against the observed data

```{r simultae from posterior vs}

# get osterior predictions
stan_pred <- posterior_predict(stan_fit$fit)

samps<-sample(1:nrow(stan_pred),
              50)

# pull from dataset
bayesplot::ppc_dens_overlay(y = stan_fit$fit$y,
                            yrep = stan_pred[samps,])

```

Here we start to run into the biggest issue with using a simple linear model for this data. This is because the geek rating is a function of both the average rating and user ratings. For predicting new games, we might be better off predicting these two quantities separately and then combining them to produce an estimated geek rating. More on that later.

##### MARS

```{r set mars mod and tuning par}

# mars model
mars_mod<-parsnip::mars(
  mode = "regression",
  engine = "earth",
  num_terms = tune::tune(),
  prod_degree = tune::tune()
)

# parameter speciofication
mars_params <- 
  dials::parameters(
    num_terms(),
    prod_degree()
    # learn_rate(),
    # loss_reduction()
  )

# grid
mars_grid <- 
  expand.grid(
    num_terms = c(5, 15, 50, 75, 115),
    prod_degree = c(1, 2, 3)
  )


```

Now fit a mars.

```{r fit mars workflow}

# build workflow
set.seed(1999)
mars_workflow<-
  workflow() %>% 
  add_model(mars_mod) %>% 
  add_recipe(recipe_baverage)

# tune
mars_results <-
  mars_workflow %>%
  tune_grid(train_folds,
            grid = mars_grid,
             control = control_grid(save_pred = TRUE),
             metrics = reg_metrics)

  # tune_grid(train_folds,
  #           grid = mars_grid,
  #           control = control_grid(save_pred = TRUE),
  #           metrics = reg_metrics)


```

Look at the results

```{r plot mars resultsr}

# plot
mars_results %>%
  collect_metrics() %>%
  mutate(model = "mars") %>%
  mutate(prod_degree = as.factor(prod_degree)) %>%
  ggplot(., aes(x=num_terms,
                group = prod_degree,
                color = prod_degree,
                y=mean))+
  geom_point()+
  geom_line()+
  facet_wrap(model~.metric,
             scales="free_y")+
  theme_phil()+
  scale_color_viridis_d()

```

Extract some basic information from this model.

```{r grab the results from mars}

# grab the best tuning results
mars_best<-mars_results %>%
  select_best("rmse", n=1)

# what were our best results
mars_results %>% 
  collect_metrics(parameters = mars_best) %>%
  mutate(model = "mars") %>%
  filter(num_terms == mars_best$num_terms,
         prod_degree == mars_best$prod_degree) %>%
  mutate_if(is.numeric, round, 3) %>%
  select(model, .metric, mean, std_err)
  
# grab the predictions and plot
mars_results %>%
  collect_predictions(parameters = mars_best) %>%
  mutate(model = "mars") %>%
  ggplot(., aes(x=.pred,
                y=baverage))+
  geom_point(alpha=0.5)+
  facet_wrap(model~.)+
  theme_phil()+
  geom_smooth(formula = y ~ x, method = "loess")+
  # coord_cartesian(xlim = c(3.5, 9),
  #                 ylim = c(3.5, 9))+
  stat_cor(label.x = 3.5,
           p.accuracy = 0.001)+
  geom_abline(slope =1,
              intercept = 0,
              col = "grey60",
              linetype = 'dashed')

```

We're less interested in using MARs as our predictive model than using it to identify interactions and nonlinearities.

```{r extract coefs from mars, warning=F}

# get model fit
mars_fit<-mars_workflow %>%
  finalize_workflow(mars_best) %>%
  fit(games_train) %>%
  extract_fit_parsnip()

# rename function
rename_func<-function(x) {
  
  x<-gsub("cat_memory", "cat_memory_game", x)
  x<-gsub("cat_","", x)
  x<-gsub("mech_","", x)
  x<-gsub("pub_","", x)
  x<-gsub("des_","", x)
  x<-gsub("avgweight", "Average Weight", x)
  x<-gsub("yearpublished", "Year Published", x)
  x<-gsub("minage", "Min Age", x)
  x<-gsub("playingtime", "Playing Time", x)
  x<-gsub("maxplayers", "Max Players", x)
  x<-gsub("minplayers", "Min Players", x)
  x<-gsub("_", " ", x)

  str_to_title(x)

}

# extract coefs
mars_fit$fit %>%
  coef(.) %>%
  tidy() %>%
  rename(term = names,
         estimate = x)  %>%
  filter(term != '(Intercept)') %>%
  mutate(term = rename_func(term)) %>%
  mutate_if(is.numeric, round, 3) %>%
  arrange(desc(estimate))

# create a grid of number_mechanics

library(pdp)

## number of mechanics
foo<-pdp::partial(mars_fit$fit,
                  train = mars_fit$fit$data,
             pred.var = "number_mechanics",
            # trim.outliers = T,
             ice=T,
             plot=F,
             type = "regression")

foo %>%
  ggplot(., aes(x=number_mechanics,
                y = yhat,
                group = yhat.id))+
  geom_path(alpha=0.25)+
  theme_minimal()

## number of mechanics
foo<-pdp::partial(mars_fit$fit,
                  train = mars_fit$fit$data,
             pred.var = "yearpublished",
            # trim.outliers = T,
             ice=T,
             plot=F,
             type = "regression")

foo %>%
  ggplot(., aes(x=yearpublished,
                y = yhat,
                group = yhat.id))+
  geom_path(alpha=0.25)+
  theme_minimal()

## avgweight
foo<-pdp::partial(mars_fit$fit,
                  train = mars_fit$fit$data,
             pred.var = "avgweight",
            # trim.outliers = T,
             ice=T,
             plot=F,
             type = "regression")

foo %>%
  ggplot(., aes(x=avgweight,
                y = yhat,
                group = yhat.id))+
  geom_path(alpha=0.25)+
  theme_minimal()

rm(foo)


```

##### KNN

```{r specify knn model}

library(kknn)

# specify knn model
knn_mod<-nearest_neighbor(
        mode = "regression",
        engine = "kknn",
        neighbors = tune::tune()
)

# generate grid
knn_grid <- expand.grid(
        neighbors = c(5,10, 15, 25, 75, 150)
)

```

Now fit the knn

```{r tune the knn}

# build workflow
set.seed(1999)
knn_workflow<-
        workflow() %>% 
        add_model(knn_mod) %>% 
        add_recipe(recipe_baverage)


# tune
knn_results <-
        knn_workflow %>%
        tune_grid(train_folds,
                  grid = knn_grid,
                  control = control_grid(save_pred = TRUE),
                  metrics = reg_metrics)

```

```{r examine tuning for knn}

knn_results %>%
        collect_metrics() %>%
        mutate(model = "knn") %>%
        ggplot(., aes(x=neighbors,
                      y= mean))+
        geom_line()+
        geom_point()+
        facet_wrap(model + .metric~.,
                   scales = "free")+
        theme_phil()



```

Collect the predictions from knn.

```{r examine results for knn}


knn_best <- knn_results %>%
        show_best("rmse", n=1)

# get predictions
knn_results %>%
        collect_predictions(parameters = knn_best) %>%
        left_join(., baked_train) %>%
        arrange(.row) %>%
        select(id, .pred, .row, baverage, game_id, name) %>%
        filter(game_id %in% samp) %>%
        arrange(desc(.pred)) %>%
        mutate(game_id = as.character(game_id)) %>%
        mutate(model = "knn") %>%
        select(model, game_id, name, baverage, .pred) %>%
        arrange(desc(baverage)) %>%
        mutate_if(is.numeric, round, 3) %>%
        flextable() %>%
        autofit() %>%
        bg(j = c('.pred', 'baverage'),
           bg = col_func)


```

##### xgbTree

Let's up the flexibility of the model and turn to our old favorite, gradient boosted trees.

```{r create xgbTree workflow}

# XGBoost model specification
xgbTree_mod <- 
  parsnip::boost_tree(
    mode = "regression",
    trees = 500,
    sample_size = tune::tune(),
    min_n = tune::tune(),
    tree_depth = tune::tune()) %>%
  set_engine("xgboost", 
               objective = "reg:squarederror")

```

Now create the tuning grid.

```{r tuning grid for xgbTree}

# parameter speciofication
xgbTree_params <- 
  dials::parameters(
    sample_size(),
    min_n(),
    tree_depth()
  )

# grod
xgbTree_grid <- 
  expand.grid(
    sample_size = c(0.5, 0.75, 0.95),
    min_n = c(5, 15, 30),
    tree_depth = 3
  )

  #             learn_rate = .c
  # dials::grid_max_entropy(
  #   xgbTree_params, 
  #   size = 5
  #)

```

Now create the workflow and tune the model.

```{r tune workflow for xgbTree}

# build workflow
set.seed(1999)
xgbTree_workflow<-
  workflow() %>% 
  add_model(xgbTree_mod) %>% 
  add_recipe(recipe_baverage)

# tune
xgbTree_results <-
  xgbTree_workflow %>%
  tune_grid(train_folds,
            grid = xgbTree_grid,
            control = control_grid(save_pred = TRUE),
            metrics = reg_metrics)

```

Gather the results as before.

```{r plot results across tuning metrics for xgbTree}

# plot
xgbTree_results %>%
  collect_metrics(summarize=F) %>%
 # select(min_n, tree_depth, sample_size, .metric, mean) %>%
  filter(.metric == 'rmse') %>%
 # filter(sample_size == 0.5) %>%
  mutate(model = "xgbTree") %>%
  ggplot(., aes(x=min_n,
                y=.estimate,
                by = id,
                dodge = sample_size))+
    geom_point()+
    geom_line()+
    facet_wrap(.metric ~ sample_size)+
  theme_phil()+
  scale_color_viridis_d()


```

Get predictions

```{r xgbtree}

xgbTree_best<-xgbTree_results %>%
  select_best("rmse")

xgbTree_results %>%
  collect_predictions(parameters = xgbTree_best) %>%
  mutate(model = "xgbTree") %>%
  arrange(.row) %>%
  ggplot(., aes(x=.pred,
                y=baverage))+
  geom_point(alpha=0.5)+
  facet_wrap(model~.)+
  theme_phil()+
  geom_smooth(formula = y ~ x, method = "loess")+
  coord_cartesian(xlim = c(3.5, 9),
                  ylim = c(3.5, 9))+
  stat_cor(label.x = 3.5,
           p.accuracy = 0.001)+
  geom_abline(slope =1,
              intercept = 0,
              col = "grey60",
              linetype = 'dashed')
  
```

look at results

```{r xgbtree pred sample, warning=F, message=F}

# get predictions
xgbTree_results %>%
  collect_predictions(parameters = xgbTree_best) %>%
  left_join(., baked_train) %>%
  arrange(.row) %>%
  select(id, .pred, .row, baverage, game_id, name) %>%
  filter(game_id %in% samp) %>%
  arrange(desc(.pred)) %>%
  mutate(game_id = as.character(game_id)) %>%
  mutate(model = "xgbTree") %>%
  select(model, game_id, name, baverage, .pred) %>%
  arrange(desc(baverage)) %>%
  mutate_if(is.numeric, round, 3) %>%
  flextable() %>%
  autofit() %>%
        bg(j = c('.pred', 'baverage'),
           bg = col_func)


```


```{r look at the predictions from the boosted trees, warning=F, message=F}

xgbTree_results %>%
  collect_predictions(parameters = xgbTree_best) %>%
  mutate(model = "xgbTree") %>% 
  arrange(.row) %>%
  left_join(., baked_train) %>%
  select(.pred, .row, baverage, game_id, name, yearpublished) %>%
  filter(yearpublished == 2019) %>%
  arrange(desc(.pred)) %>%
  mutate(pred_rank = row_number()) %>%
  arrange(desc(baverage)) %>%
  mutate(bgg_rank = row_number()) %>%
  mutate_if(is.numeric, round, 3) %>%
  rename(pred_rating = .pred,
         bgg_rating = baverage) %>%
  mutate(yearpublished = as.character(yearpublished),
         game_id = as.character(yearpublished)) %>%
  select(yearpublished, game_id, name, pred_rating, bgg_rating, pred_rank, bgg_rank) %>%
  arrange(pred_rank) %>%
  # mutate(diff_rank = pred_rank - bgg_rank) %>%
  # arrange(diff_rank) %>%
  flextable() %>%
  autofit()
  
```

plot of ranks

```{r plot rank vs rank, warning=F, message=F}

xgbTree_results %>%
  collect_predictions(parameters = xgbTree_best) %>%
  sample_n(500) %>%
  mutate(model = "xgbTree") %>%
  select(id, .row, baverage, .pred, model) %>%
  arrange(baverage) %>%
  mutate(rank = row_number()) %>%
  melt(id.vars = c("id", ".row", "model", "rank")) %>%
  ggplot(., aes(x=rank,
                y = value,
                color = variable))+
  geom_point(alpha=0.75)+
  theme_phil()+
  scale_color_manual(values = c("deepskyblue1", "navy"))+
  facet_wrap(model~.)+
  ylab("Rating")+
  xlab("Rank")+
  geom_smooth()


```
variable importance

```{r extract xgbTree model}

library(vip)

xgbTree_fit<-xgbTree_workflow %>%
  finalize_workflow(xgbTree_best) %>%
  fit(games_train) %>%
  extract_fit_parsnip()

# variable importance
vip(xgbTree_fit$fit,
    num_features =25,
    all_permutations = T) +
  theme_phil()

```
partial dependence 

```{r pdp for xgbTree, fig.height=4}

# specify tain ojb
train_obj = baked_train %>%
  select(one_of(xgbTree_fit$fit$feature_names))

# select top predictors by importance
top_predictors<-vip::vi(xgbTree_fit$fit) %>%
  slice_max(., order_by = Importance,
            n = 16) %>%
  pull(Variable)
  
library(pdp)

# create a function for partial
partial_func<-function(mod, feature, train_obj) {
  
  var<-enquo(feature)
  var1<-rlang::sym(paste(feature))
  
  foo<-pdp::partial(mod,
                  train = train_obj,
             pred.var = paste(feature),
             center =T,
         #    trim.outliers = T,
             ice=T,
             plot=F,
             type = "regression")
  
  out<-foo %>%
    as_tibble() %>%
    mutate(variable = paste(feature)) %>%
    rename(value = !!var1) %>%
    select(variable, value, yhat, yhat.id)
  
  return(out)
  
  # out %>%
  #   ggplot(., aes(x=value,
  #               y = yhat,
  #               group = yhat.id))+
  #   geom_path(alpha=0.25)+
  #   theme_minimal()+
  #   facet_wrap(variable~.)

}

# loop over top predictors
partials<-foreach(i = 1:length(top_predictors),
        .combine = rbind.data.frame) %do% {
          
          partial_func(mod = xgbTree_fit$fit,
             feature = top_predictors[i],
             train_obj = train_obj)
          
        }

# plot
partials %>%
  #filter(variable == 'number_mechanics' | variable == 'avgweight') %>%
  mutate(variable = rename_func(variable)) %>%
  ggplot(., aes(x=value,
                y = yhat))+
  geom_line(aes(group = yhat.id), alpha=0.05)+
  stat_summary(fun=median,
               geom="line",
               col = "orange",
               alpha = 0.6)+
  facet_wrap(variable~.,
               scales = "free")+
  theme_phil()+
  xlab("Feature Value")+
  ylab("Effect on Geek Rating")+
  labs(caption = str_wrap("Centered individal conditional expectation plots for top predictors from xgbTree. Model trained on board games published between 1990 and 2019 prior with at least 200 user ratings.", 125))

rm(partials)

```

Shapley values

```{r start using iml 04, warning=F, message=F}
 
library(iml)
 
# make my own prediction function
predict.function <- function(model, new_observation) {
  predict(model, new_observation)
}

X = train_obj %>% as.data.frame()
y= baked_train$baverage

# # put ranger into object
# predictor.ranger <- Predictor$new(
#   model = models_down$down_ranger,
#   data = X,
#   y = train_down$NEXT_FOUR_QUARTERS_AT_LEAST_ONE_POLICY,
#   type="prob",
#   class="yes"
#   )
 
# make function for plotting shapley values
shapley_plot<-function(predictor,
                       model_name,
                       train_data,
                       input_id,
                       threshold) {
       
        # require(ModelMetrics)
        # require(gsubfn)
        # require(conflicted)
        # 
    #    conflict_prefer("list", "base")
  
  # use model to define X object with features
  X = train_data %>%
    select(one_of(predictor$model$fit$feature_names))
  
  # look up game id in training set
  record = train_data %>%
    filter(game_id == input_id) %>%
    pull(.row)
  
 # # look up the game
  game_name<-train_data %>%
    filter(.row == record) %>%
    pull(name)
  
  id<-train_data %>%
    filter(.row == record) %>%
    pull(game_id)

  # # temp obj for the predictor
  temp<-predictor
  
  # get shapley values
  shapley <- Shapley$new(temp,
                         sample.size = 250,
                          x.interest = X[record, ])
  
  # actual vs
    average = paste("Average Game Prediction:", round(shapley$y.hat.average, 2))
    actual =  paste("Game Prediction:", round(shapley$y.hat.interest, 2))

    # plot
  plot_shap<-shapley$results %>%
                separate(feature.value, into=c("Feature", "Value"), sep="=") %>%
                mutate(Feature = rename_func(Feature),
                       Value = round(as.numeric(Value), 2)) %>%
                mutate(Feature.Value = paste(Feature, Value, sep="=")) %>%
                filter(abs(phi) > threshold) %>%
    mutate(model = paste(model_name)) %>%
                ggplot(aes(x = reorder(Feature.Value, -phi), y = phi, fill = phi)) +
        geom_hline(yintercept = 0,
               alpha = 0.5)+
                geom_bar(stat = "identity", alpha = 0.95) +

                coord_flip() +
                guides(fill=F)+
                scale_fill_gradient2_tableau(limits=c(-.02,0.02), oob = scales::squish)+
                theme_phil()+
                ggtitle(paste(
                  paste("Game: ", game_name, sep=""),
                  paste("ID: ", id, sep=""), 
                  sep = "\n"),
                        subtitle = paste(average,actual, sep = "\n"))+
                theme(plot.title = element_text(size=12),
                      axis.text.y = element_text(size=8))+
                xlab("")+
                ylab("Feature Contribution to Prediction")+
    facet_wrap(model~.)

        rm(actual, average, temp)

        return(plot_shap)

}

# put xgbTree into predictor object
predictor.xgbTree <- Predictor$new(
  model = xgbTree_fit,
  data = X,
  y = y
  )

#  
# # put glmnet into object
# predictor.glmnet <- Predictor$new(
#   model = models_down$down_glmnet_oneSE,
#   data = X,
#   y = baked_train$
#   type="prob",
#   class="yes"
#   )
 
```
 
We can then look at shapley values for a sample of games to see how the model arrived at its predictions. These will be slightly different than the predictions we observed for our games earlier, as these are using the model that was trained on the full dataset rather than the cross validated predictions.

```{r illustrate shapley values for xgbTree, warning=F, message=F, fig.height=4}
 
samp_games = c(521, 115746, 822, 204583, 15062, 84876, 192455)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[1],
             threshold=0.01)
  
shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[2],
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[3],
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[4],
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[5],
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[6],
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = samp_games[7],
             threshold=0.01)

```


```{r fig.height=4}

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = 174430,
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = 167355,
             threshold=0.01)

shapley_plot(predictor.xgbTree,
             model_name = "xgbTree",
             train_data = baked_train,
             input_id = 1406,
             threshold=0.01)

```


```{r ranger mod spec}

# ranger model
ranger_mod<- parsnip::rand_forest(
  mode = "regression",
  mtry = tune::tune()) %>%
  set_engine("ranger")

# grid
ranger_grid <- 
  expand.grid(
    mtry = c(2, 9,15, 25, 50)
  )

```

Now train the random forest.

```{r ranger workflow}

# build workflow
set.seed(1999)
ranger_workflow<-
  workflow() %>% 
  add_model(ranger_mod) %>% 
  add_recipe(recipe_baverage)

# tune
ranger_results <-
  ranger_workflow %>%
  tune_grid(train_folds,
            grid = ranger_grid,
            control = control_grid(save_pred = TRUE),
            metrics = reg_metrics)

```

Extract results by tuning parameter

```{r plot rangers tuning results, warning=F}

ranger_results %>%
  collect_metrics(summarize = F) %>%
  mutate(model = "ranger") %>%
  ggplot(., aes(x=mtry,
                color = id,
                y = .estimate))+
  geom_smooth(se = F, method = 'loess', formula = 'y~x')+
  geom_point()+
  facet_wrap(model+.metric ~.,
             scales = "free")+
  theme_phil()+
  scale_color_viridis_d()

# get best tune
ranger_best <- ranger_results %>%
  show_best(metric="rmse", n=1)


```

Finalize the fit

```{r fit of ranger}

# get fit
ranger_fit<-ranger_workflow %>%
  finalize_workflow(parameters = ranger_best) %>%
  fit(games_train) %>%
  extract_fit_parsnip()

```

We can use randomForestExplainer to dive into this.

```{r examine the tree using randomForest explainer, warning=F}

library(randomForestExplainer)


min_depth_frame <- min_depth_distribution(ranger_fit$fit) %>%
  mutate(variable = rename_func(variable)) 

```


```{r}

plot_min_depth_distribution(min_depth_frame)+
  ggtitle("Distribution of Minimal Depth")+
  scale_fill_viridis_d()+
  theme_phil()+
  guides(fill = guide_legend(nrow = 2))

```

predictions

```{r}

ranger_best<-ranger_results %>%
  show_best(metric = "rmse", n=1)

ranger_results %>%
  collect_predictions(parameters = ranger_best) %>%
  left_join(., baked_train) %>%
  arrange(.row) %>%
  select(id, .pred, .row, baverage, game_id, name) %>%
  filter(game_id %in% samp) %>%
  arrange(desc(.pred)) %>%
  mutate(game_id = as.character(game_id)) %>%
  mutate(model = "ranger") %>%
  select(model, game_id, name, baverage, .pred) %>%
  arrange(desc(baverage)) %>%
  mutate_if(is.numeric, round, 3) %>%
  flextable() %>%
  autofit() %>%
        bg(j = c('.pred', 'baverage'),
           bg = col_func)



```


## Evaluation

### 2020

```{r eval on 2020}

# set color functions
col_func<- function(x) {
  
  breaks<-quantile(x, probs = seq(0, 1, by=.1), na.rm=T) %>% as.vector()
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

# combine all
games_test<-active_games %>%
 # filter(usersrated >= 250) %>% # set a minimum threshold
  select(timestamp, game_id, name, average, baverage, usersrated) %>%
  left_join(., games_info %>% # join game info
              select(game_id, yearpublished, avgweight, minage, minplayers, maxplayers, playingtime),
            by = c("game_id")) %>%
  filter(yearpublished ==2020) %>% # use games prior to 2020 as our training set
  left_join(., game_categories %>% # join categories
              mutate(category = gsub("\\)", "", gsub("\\(", "", category))) %>%
              mutate(category = tolower(paste("cat", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", category))), sep="_"))) %>%
              mutate(has_category = 1) %>%
              select(-category_id) %>%
              pivot_wider(names_from = c("category"),
                          values_from = c("has_category"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
  left_join(., game_mechanics %>% # join mechanics
              mutate(mechanic = tolower(paste("mech", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", mechanic))), sep="_"))) %>%
              mutate(has_mechanic = 1) %>%
              select(-mechanic_id) %>%
              pivot_wider(names_from = c("mechanic"),
                          values_from = c("has_mechanic"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
       left_join(., game_designers %>% # join designers
              mutate(designer = gsub("\\)", "", gsub("\\(", "", designer))) %>%
              mutate(designer = tolower(paste("des", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", designer))), sep="_"))) %>%
              mutate(has_designer = 1) %>%
              select(-designer_id) %>%
              pivot_wider(names_from = c("designer"),
                          values_from = c("has_designer"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) 

# glmnet
glmnet_pred<-glmnet_workflow %>%
  finalize_workflow(parameters = glmnet_best) %>%
  fit(games_train) %>%
  predict(games_test)

# stan
stan_pred<-stan_lm_workflow %>%
  fit(games_train) %>%
  predict(games_test)

# knn
knn_pred<-knn_workflow %>%
  finalize_workflow(parameters = knn_best) %>%
  fit(games_train) %>%
  predict(games_test)

# xgbTree
xgbTree_pred<-xgbTree_workflow %>%
  finalize_workflow(parameters = xgbTree_best) %>%
  fit(games_train) %>%
  predict(games_test)

# ranger
ranger_pred<-ranger_workflow %>%
  finalize_workflow(parameters = ranger_best) %>%
  fit(games_train) %>%
  predict(games_test)

```

Combine and look

```{r eval 2020 preds}

preds_2020<-data.frame("glmnet" = glmnet_pred$.pred,
           "stan_lm" = stan_pred$.pred,
           "knn" = knn_pred$.pred,
           "ranger" = ranger_pred$.pred,
           "xgbTree" = xgbTree_pred$.pred) %>%
  cbind.data.frame(games_test) %>%
  arrange(desc(stan_lm)) %>%
  mutate(yearpublished = as.character(yearpublished),
         game_id = as.character(game_id)) %>%
  select(yearpublished, 
         game_id, 
         name, 
         average,
         baverage, 
         glmnet,
         stan_lm, 
         knn,
         ranger,
         xgbTree) 

# table
preds_2020 %>%
  select(-average) %>%
  mutate_if(is.numeric, round, 2) %>%
  arrange(desc(baverage)) %>%
  flextable() %>%
  autofit() %>%
  bg(j = c('baverage', 'glmnet', 'stan_lm', 'knn', 'xgbTree', 'ranger'),
  bg = col_func)

# metrics
preds_2020 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>% 
  group_by(yearpublished, variable) %>%
  reg_metrics(truth = baverage,
              estimate = value) %>%
  ggplot(., aes(y=reorder(variable, .estimate),
                x=.estimate))+
  geom_point()+
  facet_wrap(yearpublished+.metric~., scales="free",
             ncol = 2)+
  theme_phil()+
  ylab("Model")

# plot vs baverage
preds_2020 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>%
  ggplot(., aes(x=baverage,
                y=value))+
  geom_point(alpha=0.5)+
  facet_wrap(yearpublished+variable~.)+
  theme_phil()+
  geom_smooth(method = 'loess', formula = 'y ~ x')+
  stat_cor(p.accuracy=.01)+
  geom_abline(slope=1, intercept = 0)


# xgbtree and stan
preds_2020 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=stan_lm))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# ranger and xgbtree
preds_2020 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=ranger))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# xgbtree and knn
preds_2020 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=knn))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())
  # coord_cartesian(xlim=c(5,8.5),
  #                 ylim =c(5, 8.5))+
  # scale_color_gradient2_tableau(limits=c(6,6.5),
  #                               oob = scales::squish)+
  # guides(color = guide_colorbar(barwidth=10,
  #                               barheight=0.5,
  #                               title.position = 'top',
  #                               title = "Geek Rating"))


```


### 2021

```{r eval on 2021}

# set color functions
col_func<- function(x) {
  
  breaks<-quantile(x, probs = seq(0, 1, by=.1), na.rm=T) %>% as.vector()
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

# combine all
games_test<-active_games %>%
 # filter(usersrated >= 250) %>% # set a minimum threshold
  select(timestamp, game_id, name, average, baverage, usersrated) %>%
  left_join(., games_info %>% # join game info
              select(game_id, yearpublished, avgweight, minage, minplayers, maxplayers, playingtime),
            by = c("game_id")) %>%
  filter(yearpublished ==2021) %>% # use games prior to 2021 as our training set
  left_join(., game_categories %>% # join categories
              mutate(category = gsub("\\)", "", gsub("\\(", "", category))) %>%
              mutate(category = tolower(paste("cat", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", category))), sep="_"))) %>%
              mutate(has_category = 1) %>%
              select(-category_id) %>%
              pivot_wider(names_from = c("category"),
                          values_from = c("has_category"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
  left_join(., game_mechanics %>% # join mechanics
              mutate(mechanic = tolower(paste("mech", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", mechanic))), sep="_"))) %>%
              mutate(has_mechanic = 1) %>%
              select(-mechanic_id) %>%
              pivot_wider(names_from = c("mechanic"),
                          values_from = c("has_mechanic"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
       left_join(., game_designers %>% # join designers
              mutate(designer = gsub("\\)", "", gsub("\\(", "", designer))) %>%
              mutate(designer = tolower(paste("des", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", designer))), sep="_"))) %>%
              mutate(has_designer = 1) %>%
              select(-designer_id) %>%
              pivot_wider(names_from = c("designer"),
                          values_from = c("has_designer"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) 

# glmnet
glmnet_pred<-glmnet_workflow %>%
  finalize_workflow(parameters = glmnet_best) %>%
  fit(games_train) %>%
  predict(games_test)

# stan
stan_pred<-stan_lm_workflow %>%
  fit(games_train) %>%
  predict(games_test)

# knn
knn_pred<-knn_workflow %>%
  finalize_workflow(parameters = knn_best) %>%
  fit(games_train) %>%
  predict(games_test)

# xgbTree
xgbTree_pred<-xgbTree_workflow %>%
  finalize_workflow(parameters = xgbTree_best) %>%
  fit(games_train) %>%
  predict(games_test)

# ranger
ranger_pred<-ranger_workflow %>%
  finalize_workflow(parameters = ranger_best) %>%
  fit(games_train) %>%
  predict(games_test)

```

Combine and look

```{r eval 2021 preds}

preds_2021<-data.frame("glmnet" = glmnet_pred$.pred,
           "stan_lm" = stan_pred$.pred,
           "knn" = knn_pred$.pred,
           "ranger" = ranger_pred$.pred,
           "xgbTree" = xgbTree_pred$.pred) %>%
  cbind.data.frame(games_test) %>%
  arrange(desc(stan_lm)) %>%
  mutate(yearpublished = as.character(yearpublished),
         game_id = as.character(game_id)) %>%
  select(yearpublished, 
         game_id, 
         name, 
         average,
         baverage, 
         glmnet,
         stan_lm, 
         knn,
         ranger,
         xgbTree) 

# table
preds_2021 %>%
  select(-average) %>%
  mutate_if(is.numeric, round, 2) %>%
  arrange(desc(baverage)) %>%
  flextable() %>%
  autofit() %>%
  bg(j = c('baverage', 'glmnet', 'stan_lm', 'knn', 'xgbTree', 'ranger'),
  bg = col_func)

# metrics
preds_2021 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>% 
  group_by(yearpublished, variable) %>%
  reg_metrics(truth = baverage,
              estimate = value) %>%
  ggplot(., aes(y=reorder(variable, .estimate),
                x=.estimate))+
  geom_point()+
  facet_wrap(yearpublished+.metric~., scales="free",
             ncol = 2)+
  theme_phil()+
  ylab("Model")

# plot vs baverage
preds_2021 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>%
  ggplot(., aes(x=baverage,
                y=value))+
  geom_point(alpha=0.5)+
  facet_wrap(yearpublished+variable~.)+
  theme_phil()+
  geom_smooth(method = 'loess', formula = 'y ~ x')+
  stat_cor(p.accuracy=.01)+
  geom_abline(slope=1, intercept = 0)


# xgbtree and stan
preds_2021 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=stan_lm))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# ranger and xgbtree
preds_2021 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=ranger))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# xgbtree and knn
preds_2021 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=knn))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())
  # coord_cartesian(xlim=c(5,8.5),
  #                 ylim =c(5, 8.5))+
  # scale_color_gradient2_tableau(limits=c(6,6.5),
  #                               oob = scales::squish)+
  # guides(color = guide_colorbar(barwidth=10,
  #                               barheight=0.5,
  #                               title.position = 'top',
  #                               title = "Geek Rating"))


```





### 2022

```{r eval on 2022}

# set color functions
col_func<- function(x) {
  
  breaks<-quantile(x, probs = seq(0, 1, by=.2), na.rm=T) %>% as.vector()
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("red", "white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}


# combine all
games_test<-active_games %>%
 # filter(usersrated >= 250) %>% # set a minimum threshold
  select(timestamp, game_id, name, average, baverage, usersrated) %>%
  left_join(., games_info %>% # join game info
              select(game_id, yearpublished, avgweight, minage, minplayers, maxplayers, playingtime),
            by = c("game_id")) %>%
  filter(yearpublished ==2022) %>% # use games prior to 2022 as our training set
  left_join(., game_categories %>% # join categories
              mutate(category = gsub("\\)", "", gsub("\\(", "", category))) %>%
              mutate(category = tolower(paste("cat", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", category))), sep="_"))) %>%
              mutate(has_category = 1) %>%
              select(-category_id) %>%
              pivot_wider(names_from = c("category"),
                          values_from = c("has_category"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
  left_join(., game_mechanics %>% # join mechanics
              mutate(mechanic = tolower(paste("mech", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", mechanic))), sep="_"))) %>%
              mutate(has_mechanic = 1) %>%
              select(-mechanic_id) %>%
              pivot_wider(names_from = c("mechanic"),
                          values_from = c("has_mechanic"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) %>%
       left_join(., game_designers %>% # join designers
              mutate(designer = gsub("\\)", "", gsub("\\(", "", designer))) %>%
              mutate(designer = tolower(paste("des", gsub("[[:space:]]", "_", gsub("\\s+", " ", gsub("[[:punct:]]","", designer))), sep="_"))) %>%
              mutate(has_designer = 1) %>%
              select(-designer_id) %>%
              pivot_wider(names_from = c("designer"),
                          values_from = c("has_designer"),
                          id_cols = c("game_id"),
                          names_sep = "_",
                          values_fn = min,
                          values_fill = 0),
            by = c("game_id")) 

# glmnet
glmnet_pred<-glmnet_workflow %>%
  finalize_workflow(parameters = glmnet_best) %>%
  fit(games_train) %>%
  predict(games_test)

# stan
stan_pred<-stan_lm_workflow %>%
  fit(games_train) %>%
  predict(games_test)

# knn
knn_pred<-knn_workflow %>%
  finalize_workflow(parameters = knn_best) %>%
  fit(games_train) %>%
  predict(games_test)

# xgbTree
xgbTree_pred<-xgbTree_workflow %>%
  finalize_workflow(parameters = xgbTree_best) %>%
  fit(games_train) %>%
  predict(games_test)

# ranger
ranger_pred<-ranger_workflow %>%
  finalize_workflow(parameters = ranger_best) %>%
  fit(games_train) %>%
  predict(games_test)

```

Combine and look

```{r eval 2022 preds}

preds_2022<-data.frame("glmnet" = glmnet_pred$.pred,
           "stan_lm" = stan_pred$.pred,
           "knn" = knn_pred$.pred,
           "ranger" = ranger_pred$.pred,
           "xgbTree" = xgbTree_pred$.pred) %>%
  cbind.data.frame(games_test) %>%
  arrange(desc(stan_lm)) %>%
  mutate(yearpublished = as.character(yearpublished),
         game_id = as.character(game_id)) %>%
  select(yearpublished, 
         game_id, 
         name, 
         average,
         baverage, 
         glmnet,
         stan_lm, 
         knn,
         ranger,
         xgbTree) 

# table
preds_2022 %>%
  select(-average) %>%
  mutate_if(is.numeric, round, 2) %>%
  arrange(desc(baverage)) %>%
  flextable() %>%
  autofit() %>%
  bg(j = c('baverage', 'glmnet', 'stan_lm', 'knn', 'xgbTree', 'ranger'),
  bg = col_func)

# metrics
preds_2022 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>% 
  group_by(yearpublished, variable) %>%
  reg_metrics(truth = baverage,
              estimate = value) %>%
  ggplot(., aes(y=reorder(variable, .estimate),
                x=.estimate))+
  geom_point()+
  facet_wrap(yearpublished+.metric~., scales="free",
             ncol = 2)+
  theme_phil()+
  ylab("Model")

# plot vs baverage
preds_2022 %>%
  melt(id.vars = c("yearpublished", "game_id", "name", "baverage", "average")) %>%
  ggplot(., aes(x=baverage,
                y=value))+
  geom_point(alpha=0.5)+
  facet_wrap(yearpublished+variable~.)+
  theme_phil()+
  geom_smooth(method = 'loess', formula = 'y ~ x')+
  stat_cor(p.accuracy=.01)+
  geom_abline(slope=1, intercept = 0)


# xgbtree and stan
preds_2022 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=stan_lm))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# ranger and xgbtree
preds_2022 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=ranger))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())

# xgbtree and knn
preds_2022 %>%
  ggplot(., aes(x=xgbTree,
                label = name,
             #   color = baverage,
                y=knn))+
  geom_text(check_overlap =T)+
  geom_point(alpha=0.8)+
 # stat_cor(p.accuracy=0.01)+
  theme_phil()+
  theme(legend.title = element_text())
  # coord_cartesian(xlim=c(5,8.5),
  #                 ylim =c(5, 8.5))+
  # scale_color_gradient2_tableau(limits=c(6,6.5),
  #                               oob = scales::squish)+
  # guides(color = guide_colorbar(barwidth=10,
  #                               barheight=0.5,
  #                               title.position = 'top',
  #                               title = "Geek Rating"))


```

Predictions

```{r write out as csv}


preds_out<-bind_rows(preds_2020,
                     preds_2021,
                     preds_2022) %>%
  mutate(date = Sys.Date()) %>%
  select(date, everything())

fwrite(preds_out, file = paste("game_predictions_data/baverage_", Sys.Date(),".csv", sep=""))


```


Models

```{r save models}

model_names <-ls(pattern = "_fit")
models = lapply(ls(pattern = "_fit"), get)
names(models)=model_names
save(models, file = paste("game_predictions_models/baverage_", Sys.Date(), ".csv", sep=""))

```

