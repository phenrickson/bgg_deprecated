---
title: "Predicting User Ratings"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
    keep_md: true
---

This notebook is for building predictive models of boardgame ratings.

```{r global seetings, echo=F, warning=F, message=F}

knitr::opts_chunk$set(echo = F,
                      dev="png",
                      fig.width = 8,
                      fig.height = 8)

options(knitr.duplicate.label = "allow")

options(scipen=999)

```

```{r load and set packages, warning=F, message=F, include=FALSE, results = 'hide'}

source("load_packages.R")
source("theme_phil.R")

```

## Get Data from Big Query

### Active Game Rankings

We'll first connect to the most recent day of BGG data that we have in our database. These are the active rankings of games - where they stand in the BGG database as of the most recent load, which I usually update once a week.

```{r connect to big query}

library(bigrquery)

# get project credentials
PROJECT_ID <- "gcp-analytics-326219"
BUCKET_NAME <- "test-bucket"


# establish connection
bigquerycon<-dbConnect(
        bigrquery::bigquery(),
        project = PROJECT_ID,
        dataset = "bgg"
)

```


```{r query active games}

# query table
active_games<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_daily')

```

### Additional Game Information

We also want to pull down other tables containing the information that we know about games.

```{r query tables with game information}

# general game info
games_info<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.active_games_info')

# game categories
game_categories<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.category_id,
                              b.category
                              FROM bgg.game_categories a
                               LEFT JOIN bgg.category_ids b 
                               ON a.category_id = b.category_id') 

# game mechanics
game_mechanics<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.mechanic_id,
                              b.mechanic
                              FROM bgg.game_mechanics a
                               LEFT JOIN bgg.mechanic_ids b 
                               ON a.mechanic_id = b.mechanic_id')

# game publishers
game_publishers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.publisher_id,
                              b.publisher
                              FROM bgg.game_publishers a
                               LEFT JOIN bgg.publisher_ids b 
                               ON a.publisher_id = b.publisher_id')

# game designers
game_designers<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT 
                              a.game_id,
                              b.designer_id,
                              b.designer
                              FROM bgg.game_designers a
                               LEFT JOIN bgg.designer_ids b 
                               ON a.designer_id = b.designer_id')

# # game artists
# game_artists<-DBI::dbGetQuery(bigquerycon, 
#                               'SELECT 
#                               a.game_id,
#                               b.artist_id,
#                               b.artist
#                               FROM bgg.game_artists a
#                                LEFT JOIN bgg.artist_ids b 
#                                ON a.artist_id = b.artist_id')


```

Historical data.

```{r query historical table}
# query table
games_ts<-DBI::dbGetQuery(bigquerycon, 
                              'SELECT * FROM bgg.historical_game_rankings')


```

Now split.

```{r split into train and test}

# specify end date
train_end_date = '2021-01-01'

# split
games_ts_train<-games_ts %>%
  filter(date < train_end_date)

games_ts_test<-games_ts %>%
  filter(date >= train_end_date)


```

We'll then convert these into tsibbles.

```{r convert to tsibble}

# function for repeating last non VA value for filling in gaps in the data
repeat.before = function(x) {   # repeats the last non NA value. Keeps leading NA
        ind = which(!is.na(x))      # get positions of nonmissing values
        if(is.na(x[1]))             # if it begins with a missing, add the 
                ind = c(1,ind)        # first position to the indices
        rep(x[ind], times = diff(   # repeat the values at these indices
                c(ind, length(x) + 1) )) # diffing the indices + length yields how often 
} 

# tsibble train
games_tsibble_train<- games_ts_train %>%
        filter(!are_duplicated(games_ts_train, index=date, key=game_id)) %>% # remove duplicates
        filter(game_id %in% games_info$game_id) %>%  # filter to only games that we have active records on
        as_tsibble(index = date,
                   key = game_id) %>%
        tsibble::fill_gaps(., .full=FALSE) %>%
        mutate_at(c("game_release_year", 
                    "bgg_rank",
                    "bgg_average",
                    "bayes_average",
                    "users_rated"),
                  repeat.before) 

```

This dataset lets us track how a game's user ratings, geek rating, and average rating has changed over time.

```{r look at samples of games}

# sample of games
samp_ids=c(521,
        268864,
        167355,
        199478)

# plot
samp_plots<-foreach(i = 1:length(samp_ids)) %do% {
  
  samp_id = samp_ids[i]
  
    # plot
  games_tsibble_train %>% 
          filter(game_id == samp_id) %>% 
          rename(`Users Rated` = users_rated,
                 `BGG Average Rating` = bgg_average,
                 `BGG Geek Rating` = bayes_average,
                 `BGG Rank` = bgg_rank) %>%
          autoplot(vars(`Users Rated`,
                        `BGG Average Rating`,
                        `BGG Geek Rating`))+
       #   theme_minimal()+
    scale_x_date(labels = date_format("%Y"))+
    xlab("")+
    theme_minimal()+
    ggtitle(paste("Game Title:", games_info %>%
    filter(game_id == samp_id) %>%
    pull(name),
    sep = " "))
  
}

samp_plots[1][[1]]
samp_plots[2][[1]]
samp_plots[4][[1]]

```

Our goal is to forecast the number of user ratings a game will get after it enters the BGG database. We're really just trying to figure out whether a game will be popular or not. We could treat this as a classification problem and create a binary outcome at a set threshold such as >1000 user ratings within one year of release. We could then just try to model the probability that a game will catch on.

Alternatively, we can treat this is a regression problem and try to directly model the number of user ratings a game will get. We could then simulate from the model to directly to identify the number of times a game passed certain thresholds, as well as the uncertainty in our ability to forecast this outcome.

Either way, we need to define some sort of end point. Given the amount of data we have, the most reasonable starting point that I can see is to try to predict how many user ratings a game will have one year after it enters the BGG database. This is imperfect for a lot of reasons, but one big issue in particular is the timing of board game releases, especially during the pandemic. Games might start showing up on BGG but due to shipping issues we won't see enough user copies reach the hands of users within a year.

Nemesis, for instance, took awhile to gather momentum on BGG.

```{r show a plot of nemesis}

samp_plots[3][[1]]

```

We'll probably want to additionally predict a two year window to see how it differs due to the pandemic.

We'd additionally like to simply forecast games given where they already are years after their release. We'll circle back to that in a bit.

### Games Released

In a perfect world, we would have data on all games after their release. But we only have historical snapshot data starting towards the end of 2016. From this, we can track when games that were released/and or achieved 30 votes after this date. In our training set, this means we can track games that showed up in BGG from 2016 to 2019. Some guys that will eventually be published in 2021 and 2022 start showing up as well, so we'll filter to games published during this time as well.

```{r dataset of games released}

# get games that started
games_started<-games_tsibble_train %>% 
        ungroup() %>%
        mutate(minimum_date = min(date)) %>%
        group_by(game_id) %>%
        mutate(start_date = min(date)) %>%
        ungroup() %>%
        filter(start_date > minimum_date) %>%
        filter(date == start_date) %>%
        left_join(., games_info %>%
                          select(game_id, yearpublished),
                  by = c("game_id")) %>%
        select(game_id, start_date, yearpublished) %>%
        filter(yearpublished > 2015 & yearpublished < year(train_end_date))

# number of games released per year
games_started %>%
        as.data.frame() %>%
        group_by(yearpublished) %>%
        summarize(games_released = n_distinct(game_id))

```

This gives us a few thousand games to track after their release. We can take a look at what these games are in a table:

```{r table  of games released}

# let's look at the games that started and were released during this time period
games_info %>% 
        filter(game_id %in% (games_started %>%
                                     filter(yearpublished > 2015) %>%
                                     pull(game_id))) %>%
        left_join(., games_started,
                  by= c("game_id", "yearpublished")) %>%
        select(game_id, name, start_date, yearpublished) %>%
        arrange(yearpublished) %>%
        mutate_if(is.numeric, as.character) %>%
  arrange(start_date) %>%
        rename(`Game ID` = game_id,
               Name = name,
               `Year Published` = yearpublished,
               `Start Date` = start_date) %>%
        DT::datatable(class = 'cell-border stripe')

```

Some of these games would go on to be pretty popular. We can plot their post release outcomes to see what typically happens.

```{r plot the user ratings over time, fig.height=4}

set.seed(1999)
games_tsibble_train %>%
        filter(game_id %in% games_started$game_id) %>%
        ungroup() %>%
        mutate(minimum_date = min(date)) %>%
        ungroup() %>%
        group_by(game_id) %>%
        mutate(start_date = min(date)) %>%
        ungroup() %>%
        mutate(days_since_start = date-start_date) %>%
        ungroup() %>%
        filter(game_id %in% (games_started %>%
                                     filter(yearpublished > 2015 & yearpublished < 2020) %>%
                                     sample_n(1000) %>% pull(game_id))) %>%
        as_tsibble(index = days_since_start, key = game_id) %>%
    mutate(`Users Rated (logged)` = log(users_rated)) %>%
        rename(`Users Rated` = users_rated,
               `BGG Average Rating` = bgg_average,
               `BGG Geek Rating` = bayes_average,
               `BGG Rank` = bgg_rank) %>%
        filter(days_since_start <= 720) %>%
  select(-`BGG Rank`) %>%
  melt(., id.vars = c("date", "game_id", "game_release_year", "minimum_date", "start_date", "days_since_start")) %>%
        ggplot(., aes(x=days_since_start,
                      y=value))+
        geom_line(aes(group = game_id),
                  alpha = 0.5,
                  lwd = .5)+
        facet_wrap(variable~., scales="free_y")+
        geom_smooth()+
        theme_phil()+
        xlab("Days Since Game Hit 30 User Ratings \n Games Published After 2015")+
        labs(caption = str_wrap("Displaying a sample of 100 games that first hit 30 user ratings after 2016-10-12 and were published between 2016 and 2019", 125))



```

A game's average rating tends to drop over time, while its geek rating tends to go up, and users rated is, of course, strictly positive, though some games have very different growth rates.

```{r plot the growth}

set.seed(1999)
games_tsibble_train %>%
        filter(game_id %in% games_started$game_id) %>%
        ungroup() %>%
        mutate(minimum_date = min(date)) %>%
        ungroup() %>%
        group_by(game_id) %>%
        mutate(start_date = min(date)) %>%
        ungroup() %>%
        mutate(days_since_start = date-start_date) %>%
        ungroup() %>%
        filter(game_id %in% (games_started %>%
                               pull(game_id))) %>%
  as_tibble() %>%
  mutate(users_rated_log = log(users_rated)) %>%
  mutate(flag = case_when(days_since_start < 5 & users_rated > 100 ~ 1,
                          TRUE~ 0)) %>%
  filter(flag != 1) %>%
  filter(days_since_start <= 365) %>%
  mutate(days_since_start = as.numeric(days_since_start)) %>%
  ggplot(., aes(x=days_since_start,
                y=users_rated_log))+
  geom_point(alpha=0.25,
             size = 0.05)+
  theme_phil()+
  geom_smooth()

# set.seed(1999)
# games_tsibble_train %>%
#         filter(game_id %in% games_started$game_id) %>%
#         ungroup() %>%
#         mutate(minimum_date = min(date)) %>%
#         ungroup() %>%
#         group_by(game_id) %>%
#         mutate(start_date = min(date)) %>%
#         ungroup() %>%
#         mutate(days_since_start = date-start_date) %>%
#         ungroup() %>%
#         filter(game_id %in% (games_started %>%
#                                pull(game_id))) %>%
#   as_tibble() %>%
#  # mutate(users_rated_log = log(users_rated)) %>%
#   mutate(flag = case_when(days_since_start < 5 & users_rated > 100 ~ 1,
#                           TRUE~ 0)) %>%
#   filter(flag != 1) %>%
#   filter(days_since_start <= 365) %>%
#   mutate(days_since_start = as.numeric(days_since_start)) %>%
#   ggplot(., aes(x=log1p(days_since_start),
#                 y=log(users_rated)))+
#   geom_point(alpha=0.25,
#              size = 0.05)+
#   theme_phil()+
#   geom_smooth()

```

What is the correlation between users rated and its lags?

```{r lags of users rated}

# horizon
horizon = 365
lag_seq = round(seq(1, horizon, length.out = 25), 0)

# create dataset 
games_tsibble_train %>%
        filter(game_id %in% games_started$game_id) %>%
  left_join(., games_started %>%
              as_tibble() %>%
              select(-date, -yearpublished)) %>%
  filter(year(start_date) < 2018) %>%
  as_tibble() %>%
  left_join(., games_info,
            by = c("game_id")) %>%
  as_tibble() %>%
  mutate(days_since_start = as.numeric(date - start_date)) %>%
  group_by(game_id) %>%
  mutate(game_horizon_max = max(days_since_start)) %>%
  filter(game_horizon_max >=horizon) %>%
  filter(days_since_start <=horizon) %>%
  timetk::tk_augment_lags(., users_rated, .lags = lag_seq) %>%
  ungroup() %>%
  select(starts_with("users_rated")) %>%
  cor(use = "pairwise.complete.obs") %>%
  as_tibble() %>%
  mutate(lags = c(0, lag_seq)) %>%
  select(users_rated, lags) %>%
  filter(lags > 0) %>%
  ggplot(., aes(x=lags, 
         y= users_rated))+
  geom_point(size=0.5)+
  geom_line()+
  theme_minimal()+
  coord_cartesian(ylim = c(0, 1))

```

User ratings are generally pretty slow moving; a game's rating at time T is pretty closely related to where it was up to 200 days ago.

```{r now set up forecating function}
 
time_vars<-c("users_rated",
             "bgg_average",
             "bayes_average")

# horizons we will forecast
horizons<-c(7, 30, 60, 90, 180)

# create function
prep_ts_direct_func<-function(data, 
                              horizon_length, 
                              lag_vars) {
  
  # specify lag set up
   if (horizon_length == 7) {
      lag_structure = c(7)
      }
    else if (horizon_length == 30) {
      lag_structure = c(15, 30)
    }
  else if (horizon_length == 60) {
    lag_structure = c(15, 30, 60)
  } 
  else if (horizon_length == 90) {
    lag_structure = c(30, 60, 90)
  }
  else if (horizon_length == 180) {
    lag_structure = c(30, 60, 90, 120, 150, 180)
  }
  else {
    paste("specify a lag structure")
  } 
  
  # manipulate data
  data %>%
    as.data.frame() %>%
    mutate(horizon = paste(horizon_length, "days", sep=" ")) %>%
    group_by(game_id) %>%
    arrange(game_id, date) %>%
    mutate(game_horizon_max = max(days_since_start)) %>%
    ungroup() %>%
    filter(game_horizon_max >= horizon_length) %>%
 #   filter(days_since_start <= horizon_length) %>%
    # group_by(days_since_start) %>%
    # summarize(games = n_distinct(game_id)) %>%
    # arrange(days_since_start)
    # filter(days_since_start <= horizon_length) 
    select(horizon,
           game_id,
           days_since_start,
           start_date,
           date, 
           everything()) %>%
    mutate(month = lubridate::month(date, label=T),
           day = lubridate::wday(date, label=T)) %>%
    group_by(game_id) %>%
    # timetk::tk_augment_lags(., 
    #                         .value = one_of(lag_vars),
    #                         .lags = lag_structure) %>%
    timetk::tk_augment_leads(.value = one_of(lag_vars),
                          .lags = -horizon_length,
                          .names = paste("lead", c(lag_vars), sep="_")) %>%
 #   filter(days_since_start == 0) %>%
 #   timetk::tk_augment_lags(one_of(lag_vars), .lags=lag_structure) %>%
   # filter(days_since_start == horizon_length) %>%
    ungroup() %>%
    filter(complete.cases(.)) %>%
    nest(-horizon)
    
}

```

Create a recipe for modeling.

```{r recipe}

end_publish_year = 2018

games_started_train=games_tsibble_train %>%
  filter(game_id %in% games_started$game_id) %>%
  left_join(., games_started %>%
              as_tibble() %>%
              select(-date, -yearpublished),
            by = c("game_id")) %>%
  left_join(., games_info,
            by = c("game_id")) %>%
  filter(yearpublished < end_publish_year) %>%
  filter(year(start_date) < end_publish_year) %>%
  as_tibble()

  #    mutate(minimum_date = min(date)) %>%
  #       ungroup() %>%
  #       group_by(game_id) %>%
  #       mutate(start_date = min(date)) %>%
  #       ungroup() %>%
  #       mutate(days_since_start = date-start_date) %>%
  #       ungroup() %>%
  # filter(yearpublished <= 2018) %>%
  # filter(days_since_start <= 365) %>%
  # as_tibble()

# create a recipe for the time series
recipe_ts <- recipe(~., x = games_started_train) %>%
  step_filter(yearpublished > 2015) %>%
  step_filter(!is.na(start_date)) %>%
  step_mutate(days_since_start = as.numeric(date - start_date+1)) %>%
  step_mutate(users_rated = log(users_rated)) %>%
  # step_mutate(days_since_start = as.numeric(date - start_date),
  #             days_since_release = as.numeric(date - release_date),
  #             days_diff_start_release = as.numeric(start_date = release_date))
  step_impute_median(yearpublished, 
                     avgweight,
                    minplayers,
                    maxplayers,
                    playingtime,
                    minplaytime,
                    maxplaytime,
                    minage) %>%
  step_mutate(playingtime = log1p(playingtime))

# bake
baked_started_train<- recipe_ts %>%
  prep(games_started_train, strings_as_factors = F) %>%
  bake(new_data = NULL)

```

Create modeling functions

```{r create model functions}

# regular naive cross validation
ctrlParallel <- trainControl(method = "repeatedcv",
                             number = 5,
                             repeats=5,
                             allowParallel = T,
                             verboseIter = F,
                             #         selectionFunction="oneSE",
                             savePredictions="final")

# one standard error
ctrloneSE <- trainControl(method = "repeatedcv",
                             number = 5,
                             repeats=5,
                             allowParallel = T,
                             verboseIter = F,
                          selectionFunction="oneSE",
                             savePredictions="final")

# regular naive cross validation
ctrlParallelNoRepeat <- trainControl(method = "cv",
                             number = 5,
                             allowParallel = T,
                             verboseIter = F,
                             #         selectionFunction="oneSE",
                             savePredictions="final")

# linear model
lm_cv<- function(df, outcome_var) {
  
  form<-as.formula(paste(
    paste(paste("lead",
                outcome_var,
                sep="_"),
   # paste("days_since_start",
          paste("bgg_average",
      #    "bayes_average",
          "users_rated",
          "avgweight",
      #    "playingtime",
       #   "minplayers",
        #  "maxplayers",
          sep="+"),
          sep="~")
  )
  )
  
  set.seed(1999)
  train(form,
        data = df,
     #   preProcess=c("center", "scale"),
        method = "lm",
        trControl = ctrlParallelNoRepeat)

}

# linear model with days since start
lm_days_cv<- function(df, outcome_var) {
  
  form<-as.formula(paste(
    paste(paste("lead",
                outcome_var,
                sep="_"),
    paste("days_since_start",
          "bgg_average",
      #    "bayes_average",
          "users_rated",
          "avgweight",
      #    "playingtime",
       #   "minplayers",
        #  "maxplayers",
          sep="+"),
          sep="~")
  )
  )
  
  set.seed(1999)
  train(form,
        data = df,
     #   preProcess=c("center", "scale"),
        method = "lm",
        trControl = ctrlParallelNoRepeat)

}

# linear model with interactions
lm_interactions_cv<- function(df, outcome_var) {
  
form = as.formula(paste(
  paste(paste("lead",
                        outcome_var,
                        sep="_"),
                  paste("days_since_start",
                        "bgg_average",
                        "users_rated",
                        "avgweight",
                        "days_since_start*users_rated",
                        "days_since_start*bgg_average",
                        "users_rated*bgg_average",
                        sep=" + "),
                  sep= "~")
)
)

  
  set.seed(1999)
  train(form,
        data = df,
     #   preProcess=c("center", "scale"),
        method = "lm",
        trControl = ctrlParallelNoRepeat)

}



# # penalized logit
# glmnet_cv<- function(df, outcome_var) {
#   
#   form<-as.formula(paste(
#     paste(paste("lead",
#                 outcome_var,
#                 sep="_"),
#           paste("bgg_average",
#           "bayes_average",
#           "users_rated",
#           "avgweight",
#           "playingtime",
#           "minplayers",
#           "maxplayers",
#           sep="+"),
#           sep="~")
#   )
#   )
#   
#   
#   set.seed(1999)
#   train(form,
#         data=df,
#         tuneGrid = expand.grid(.lambda = c(0.1, 0.25, 0.5, 0.75),
#                                    .alpha=c(.001, .002, .025, 0.05)),
#         preProcess=c("center", "scale"),
#         method = "glmnet",
#         trControl = ctrlParallelNoRepeat)
# 
# }
# 
# # xgbtree
# xgbTree_cv<- function(df, outcome_var) {
#   
#   form<-as.formula(paste(
#     paste(paste("lead",
#                 outcome_var,
#                 sep="_"),
#           paste("bgg_average",
#           "bayes_average",
#           "users_rated",
#           "avgweight",
#        #   "playingtime",
#         #  "minplayers",
#         #  "maxplayers",
#           sep="+"),
#           sep="~")
#   )
#   )
# 
#   set.seed(1999)
#   train(form,
#         data = df,
#         tuneLength = 3,
#         method = "xgbTree",
#         trControl = ctrlParallelNoRepeat)
#   
# }

```

Use forecasting function to prep the data

```{r use forecasting function, warning=F, message=F}

horizons =c(30, 90, 180, 365, 720)

## use function at each horizon length
forecasting_horizon_train<-foreach(i=1:length(horizons), .combine = bind_rows) %do% {
  
  prep_ts_direct_func(data = baked_started_train,
                    horizon_length = horizons[i],
                    lag_vars = time_vars)
  
}

forecasting_horizon_train

```

Fit the models

```{r fit models as a test}

model_results<- forecasting_horizon_train %>%
  mutate(outcome = "users_rated") %>%
  select(horizon, outcome, data) %>%
  mutate(lm = map(data, ~ lm_cv(df = .x,
                                        outcome_var = "users_rated"))) %>%
  mutate(lm_days = map(data, ~ lm_days_cv(df = .x,
                                        outcome_var = "users_rated")))
  # mutate(glmnet = map(data, ~ glmnet_cv(df = .x,
  #                                       outcome_var = "users_rated"))) %>%
  # mutate(xgbTree = map(data, ~ xgbTree_cv(df = .x,
  #                                       outcome_var = "users_rated")))
  # 
```

Glance at in sample results

```{r take a look at the results, warning=F}

# glance
model_results %>%
  mutate(glanced = map(lm, ~ .x %$%
                        finalModel %>%
                         glance(.))) %>%
  select(horizon, glanced) %>% 
  unnest() %>%
  mutate_if(is.numeric, round, 3)

# # glance
# model_results %>%
#   mutate(glanced = map(lm_interactions, ~ .x %$%
#                         finalModel %>%
#                          glance(.))) %>%
#   select(horizon, glanced) %>% 
#   unnest()


# # look at the fitted values vs the actual
# model_results[2,]$lm[[1]]$pred %>%
#   sample_n(250000) %>%
#   ggplot(., aes(x=pred, y=obs))+
#   geom_point(alpha=0.1)+
#   theme_phil()
# 
# # look glance

model_results %>%
  mutate(tidied = map(lm, ~ .x$finalModel %>%
                        tidy(se="robust", conf.int=T))) %>%
  select(horizon, tidied) %>%
  unnest() %>%
  mutate_if(is.numeric, round, 3) %>%
  filter(term != '(Intercept)') %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>% 
  filter(term == 'users_rated')
# # # look at coefs
# tidy(model_results[2,]$lm_interactions[[1]]$finalModel) %>%
#   mutate_if(is.numeric, round, 3)

```

Test out predictions with the models for a sample game.

```{r predict a sample game, warning=F}

sample_games = data.frame(days_since_start = 50,
                         bgg_average = 6.5,
                         users_rated = log(250),
                         avgweight = 2.2) %>%
  mutate(type = "average_game_with_250_ratings") %>%
  bind_rows(., data.frame(days_since_start = 50,
                         bgg_average = 6.5,
                         users_rated = log(50),
                         avgweight = 2.2) %>%
  mutate(type = "average_game_with_50_ratings")) %>%
  bind_rows(., data.frame(days_since_start = 50,
                         bgg_average = 9,
                         users_rated = log(50),
                         avgweight = 2.2) %>%
  mutate(type = "good_game_with_50_ratings")) %>%
  bind_rows(., data.frame(days_since_start = 50,
                         bgg_average = 9,
                         users_rated = log(250),
                         avgweight = 2.2) %>%
  mutate(type = "good_game_with_250_ratings"))

#sample_game = real_game[1,]

# predict with the models
bar = model_results %>%
  select(horizon, lm) %>%
  mutate(pred = map(lm, ~.x %$%
                      finalModel %>%
                      predict(., newdata = sample_games, level = .9, interval = "prediction") %>%
                      as_tibble() %>%
                      cbind.data.frame(., sample_games))) %>%
  select(horizon, pred) %>%
  unnest()

# examine
bar %>%
  mutate_at(c("fit", "lwr", "upr"),
            ~ exp(.)) %>%
  mutate_if(is.numeric, round, 0) %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>%
  bind_rows(., data.frame(horizon = 0,
                          fit = exp(sample_games$users_rated),
                          type = sample_games$type)) %>%
  mutate(day = horizon + sample_games$days_since_start) %>%
  arrange(horizon) %>%
  ggplot(., aes(x=day,
                color = type,
                fill = type,
                y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_point()+
  geom_ribbon(alpha=0.45)+
  theme_phil()+
  coord_cartesian(ylim = c(0, NA),
                  xlim = c(0, NA))+
  scale_fill_manual(values = c("red", "orange",
                               "navy", "blue"))+
  scale_color_manual(values = c("red", "orange",
                               "navy", "blue"))+
  facet_wrap(type~.,)+
  guides(fill = "none",
         color = "none")
```

Let's look at an actual game in the dataset as an example of how this works.

```{r predict flamme rouge, warning=F}

#set.seed(9)

real_game = baked_started_train %>%
 # filter(game_id == 217085) %>%
   filter(game_id == 199478) %>%
 # filter(days_since_start > 50) %>%
#  filter(days_since_start > 50) %>%
  select(date,game_id, days_since_start, users_rated, bgg_average, avgweight) %>%
  left_join(., active_games %>%
              select(game_id, name),
            by = "game_id")

samp_forecast = model_results %>%
  select(horizon, lm) %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>%
  mutate(pred = map2(lm,
                     horizon,
                     ~.x %$%
                      finalModel %>%
                      predict(., newdata = real_game, level = .9, interval = "prediction") %>%
                      as_tibble() %>%
                       cbind.data.frame(., real_game %>%
                                          select(date, game_id, users_rated)) %>%
                       mutate(date_of_forecast = date,
                              date = date+.y))) %>%
  select(horizon, pred) %>%
  unnest() 

one_day = samp_forecast %>%
  select(date, date_of_forecast, game_id, users_rated, horizon, fit, lwr, upr, users_rated) %>%
  arrange(date_of_forecast, date, horizon) %>%
  filter(lubridate::mday(date_of_forecast) == 1) %>%
  filter(lubridate::yday(date_of_forecast) == 1 | 
           lubridate:: yday(date_of_forecast) == 182 | 
           lubridate::yday(date_of_forecast) == 365) %>%
  # filter(date_of_forecast == '2017-01-15' | 
  #          date_of_forecast == '2017-09-01' |
  #          date_of_forecast == '2017-12-01' |
  #          date_of_forecast == '2017-06-01') %>%
  mutate_at(c("fit", "upr", "lwr"),
            ~ exp(.))

real_game %>%
  ggplot(., aes(x=date,
                y=exp(users_rated)))+
  geom_ribbon(data=one_day, 
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
        #        y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_line(color = "red", lwd=1.1)+
  geom_line(color = "black", data=one_day, 
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
                  fit))+
  theme_phil()+
  scale_fill_grey()+
 # geom_vline(xintercept = one_day$date_of_forecast,
  #           linetype = 'dotted')+
  theme(legend.title = element_text())+
  guides(fill = guide_legend(title = "Date of Forecast",
                             title.position = 'top'))+
  guides(fill =F)+
  labs(caption = paste(paste("Game ID: ",one_day[1,]$game_id),
                       paste("Game:", real_game[1,]$name),
                       sep="\n"))+
  ylab("Users Rated")+
  xlab("")+
  coord_cartesian(ylim = c(0, NA))+
  facet_wrap(factor(date_of_forecast)~.)

```

Let's grab a random game and do the same thing.

```{r random game, warning=F}

real_game = baked_started_train %>%
  filter(game_id == sample(baked_started_train$game_id, 1)) %>%
 # filter(game_id == 217085) %>%
  # filter(game_id == 199478) %>%
 # filter(days_since_start > 50) %>%
#  filter(days_since_start > 50) %>%
  select(date,game_id, days_since_start, users_rated, bgg_average, avgweight) %>%
  left_join(., active_games %>%
              select(game_id, name),
            by = "game_id")

samp_forecast = model_results %>%
  select(horizon, lm) %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>%
  mutate(pred = map2(lm,
                     horizon,
                     ~.x %$%
                      finalModel %>%
                      predict(., newdata = real_game, level = .9, interval = "prediction") %>%
                      as_tibble() %>%
                       cbind.data.frame(., real_game %>%
                                          select(date, game_id, users_rated)) %>%
                       mutate(date_of_forecast = date,
                              date = date+.y))) %>%
  select(horizon, pred) %>%
  unnest() 

one_day = samp_forecast %>%
  select(date, date_of_forecast, game_id, users_rated, horizon, fit, lwr, upr, users_rated) %>%
  arrange(date_of_forecast, date, horizon) %>%
  filter(lubridate::mday(date_of_forecast) == 1) %>%
  filter(lubridate::yday(date_of_forecast) == 1 | 
           lubridate:: yday(date_of_forecast) == 182 | 
           lubridate::yday(date_of_forecast) == 365) %>%
  # filter(date_of_forecast == '2017-01-15' | 
  #          date_of_forecast == '2017-09-01' |
  #          date_of_forecast == '2017-12-01' |
  #          date_of_forecast == '2017-06-01') %>%
  mutate_at(c("fit", "upr", "lwr"),
            ~ exp(.))

real_game %>%
  ggplot(., aes(x=date,
                y=exp(users_rated)))+
  geom_ribbon(data=one_day, 
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
        #        y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_line(color = "red", lwd=1.1)+
  geom_line(color = "black", data=one_day, 
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
                  fit))+
  theme_phil()+
  scale_fill_grey()+
 # geom_vline(xintercept = one_day$date_of_forecast,
  #           linetype = 'dotted')+
  theme(legend.title = element_text())+
  guides(fill = guide_legend(title = "Date of Forecast",
                             title.position = 'top'))+
  guides(fill = "none")+
  labs(caption = paste(paste("Game ID: ",one_day[1,]$game_id),
                       paste("Game:", real_game[1,]$name),
                       sep="\n"))+
  ylab("Users Rated")+
  xlab("")+
  coord_cartesian(ylim = c(0, NA))+
  facet_wrap(factor(date_of_forecast)~.)


```


## Validate Model

We'll now forecast games that were released in 2018 and see how well we did in forecasting user ratings.

```{r now bake the a validation set}

end_publish_year = 2018

games_started_valid =games_tsibble_train %>%
  filter(game_id %in% games_started$game_id) %>%
  left_join(., games_started %>%
              as_tibble() %>%
              select(-date, -yearpublished),
            by = c("game_id")) %>%
  left_join(., games_info,
            by = c("game_id")) %>%
  filter(yearpublished == end_publish_year) %>%
  filter(year(start_date) == end_publish_year) %>%
  as_tibble()

# bake
baked_started_valid<-recipe_ts %>%
  prep(games_started_train, strings_as_factor = F) %>%
  bake(games_started_valid)

```

We'll use the previously trained models to forecast these games.

```{r predict test set,  warning=F}

# use teh direct forecasting models
pred_valid<- model_results %>%
  select(horizon, lm) %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>%
  mutate(pred = map2(lm,
                     horizon,
                     ~.x %$%
                      finalModel %>%
                      predict(., newdata = baked_started_valid, level = .9, interval = "prediction") %>%
                      as_tibble() %>%
                       cbind.data.frame(., baked_started_valid %>%
                                          select(date, game_id, users_rated, days_since_start)) %>%
                       mutate(date_of_forecast = date,
                              date = date+.y))) %>%
  select(horizon, pred) %>%
  unnest() 


# specify reg metrics
reg_metrics<-metric_set(yardstick::rmse,
                        yardstick::rsq,
                        yardstick::mae,
                        yardstick::mape)


# # examine number of games by days since start
# pred_valid %>%
#   select(date_of_forecast,
#          date,
#          days_since_start,
#          game_id,
#          users_rated,
#          horizon,
#          fit,
#          lwr,
#          upr) %>%
#   arrange(game_id, date_of_forecast, horizon) %>%
#   left_join(., games_ts %>%
#               mutate(users_rated = log(users_rated)) %>%
#               select(date, game_id, users_rated) %>%
#               rename(actual = users_rated),
#            by = c("game_id", "date")) %>%
#   mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
#   mutate_at(c("fit", "lwr", "upr","actual"),
#             ~ round(exp(.), 0)) %>%
#   #filter(days_since_start <= 365) %>%
#   group_by(days_since_start) %>%
#   summarize(games = n_distinct(game_id)) %>%
#   ggplot(., aes(x=days_since_start,
#                 y=games))+
#   geom_line()+
#   theme_phil()

# examine how well we do during a game's release
pred_valid %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon) %>%
  left_join(., games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  mutate_at(c("fit", "lwr", "upr","actual"),
            ~ round(exp(.), 0)) %>%
  filter(days_since_start <= 365) %>%
  group_by(horizon, days_since_start) %>%
  reg_metrics(truth = actual,
                  estimate = fit,
                  na_rm = T) %>%
  mutate_if(is.numeric, round, 2) %>%
 # filter(horizon != 720) %>%
  ggplot(., aes(x=days_since_start,
                y=.estimate,
                color = factor(horizon)))+
  geom_line()+
  facet_wrap(.metric~.,
             scales = "free_y")+
  theme_phil()+
  scale_color_viridis_d()+
  geom_vline(xintercept = c(50,100),
             linetype = 'dashed')+
  xlab("Days Since Game Entered")+
  ylab(".estimate")+
  theme(legend.title = element_text())+
  guides(color = guide_legend(title = "Forecasting Horizon",
                              title.position = "top"))+
  labs(caption = str_wrap("Assessing forecasted user ratings for games that entered the database in 2018. Vertical lines indicate 50 and 100 day marks."))

```

If I'm interpreting things correctly, it would seem that forecasting a game based on its first few weeks of it entering the database is pretty much a crapshoot. Once we get about 50 days of data on a game, we start to have a better sense of where the game's user ratings trajectory is headed, though the uncertainty and error is naturally higher the farther out we forecast.

Our two year forecasts also start to see some issues as we get close to a year out since the game entered the database; I wonder if it's a function of print runs leading to second waves of user ratings?

At any rate, let's make a scatter plot of the forecasts for each time horizon using game info 50 days after their release.

```{r scatter forecasts, warning = F, message=F}

# set number of days
n_days = 50

# look
pred_valid %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon) %>%
  left_join(., games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  # mutate_at(c("fit", "lwr", "upr","actual"),
  #           ~ round(exp(.), 0)) %>%
  filter(days_since_start == n_days) %>%
 # filter(horizon != 720) %>%
  ggplot(., aes(x=fit,
                y=actual))+
              #  color = factor(horizon)))+
  geom_point(alpha=0.6)+
  facet_wrap(horizon~.)+
  theme_phil()+
  geom_abline(slope = 1,
              intercept = 0)+
  stat_cor(p.accuracy = .01)+
  labs(caption = str_wrap(paste("Forecasting user ratings for games released in 2018. Using data for games", n_days,"days after they first hit entered the database."), 75))

```

Compared to forecasts about a game on the first day they enter BGG.

```{r scatter forecasts 2, warning = F, message=F}

# set number of days
n_days = 1

# look
pred_valid %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon) %>%
  left_join(., games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  # mutate_at(c("fit", "lwr", "upr","actual"),
  #           ~ round(exp(.), 0)) %>%
  filter(days_since_start == n_days) %>%
 # filter(horizon != 720) %>%
  ggplot(., aes(x=fit,
                y=actual))+
              #  color = factor(horizon)))+
  geom_point(alpha=0.6)+
  facet_wrap(horizon~.)+
  theme_phil()+
  geom_abline(slope = 1,
              intercept = 0)+
  stat_cor(p.accuracy = .01)+
  labs(caption = str_wrap(paste("Forecasting user ratings for games released in 2018. Using data for games", n_days,"days after they first hit entered the database."), 75))

```

Let's look at some games that the model explicitly did not do well on.

```{r find some misses}

# look
pred_valid %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon) %>%
  left_join(., games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  # mutate_at(c("fit", "lwr", "upr","actual"),
  #           ~ round(exp(.), 0)) %>%
  filter(days_since_start == 50) %>%
  mutate(diff = actual - fit) %>%
  arrange(desc(diff))

miss_ids = c(236332,
             229853)

```

### Underestimating User Ratings

```{r look at a miss}

# get game
game_data = baked_started_valid %>%
    filter(game_id %in% c(miss_ids[2])) 
  
# get predictions
game_forecasts = pred_valid %>%
    filter(game_id %in% c(miss_ids[2])) %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon)  %>%
  left_join(.,  games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  mutate_at(c("fit", "lwr", "upr","actual"),
            ~ round(exp(.), 0)) %>%
  filter(game_id %in% c(miss_ids[2]))
  
# filter to specified days
selected_days = pred_valid %>%
  filter(game_id %in% game_data$game_id) %>%
  select(date, date_of_forecast, game_id, users_rated, horizon, fit, lwr, upr, users_rated, days_since_start) %>%
  arrange(date_of_forecast, date, horizon) %>%
  filter(days_since_start %in% c(1, 10, 50, 100, 365)) %>%
  # filter(lubridate::mday(date_of_forecast) == 1) %>%
  # filter(lubridate::yday(date_of_forecast) == 1 | 
  #          lubridate:: yday(date_of_forecast) == 182 | 
  #          lubridate::yday(date_of_forecast) == 365) %>%
  # filter(date_of_forecast == '2017-01-15' | 
  #          date_of_forecast == '2017-09-01' |
  #          date_of_forecast == '2017-12-01' |
  #          date_of_forecast == '2017-06-01') %>%
  mutate_at(c("fit", "upr", "lwr"),
            ~ exp(.))

# plot real game
game_data %>%
  ggplot(., aes(x=date,
                y=exp(users_rated)))+
  geom_ribbon(data=selected_days,
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
        #        y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_line(data=selected_days,
              alpha=0.8,
              color = "black",
              aes(x=date,
                  group = date_of_forecast,
                  y=fit))+
  geom_line(color = "red", lwd=1.1)+
  theme_phil()+
  scale_fill_grey()+
 # geom_vline(xintercept = selected_days$date_of_forecast,
  #           linetype = 'dotted')+
  theme(legend.title = element_text())+
  guides(fill = guide_legend(title = "Date of Forecast",
                             title.position = 'top'))+
  guides(fill ="none")+
  labs(caption = paste(paste("Game ID: ",selected_days[1,]$game_id),
                       paste("Game:", game_data[1,]$name),
                       sep="\n"))+
  ylab("Users Rated")+
  xlab("")+
  coord_cartesian(ylim = c(0, NA))+
  facet_wrap(factor(date_of_forecast)~.)

```

This is a miss because it showed up on BGG and didn't gather any user ratings for a while. I think this is because the game was on Kickstarter and didn't make it to backers well after the initial entry to the dataset.

```{r start at the beginning of the year}

# filter to specified days
selected_days = pred_valid %>%
  filter(game_id %in% game_data$game_id) %>%
  select(date, date_of_forecast, game_id, users_rated, horizon, fit, lwr, upr, users_rated, days_since_start) %>%
  arrange(date_of_forecast, date, horizon) %>%
  filter(date_of_forecast == '2019-01-01' | 
           date_of_forecast == '2019-05-01' |
           date_of_forecast == '2019-08-01') %>%
#  filter(days_since_start %in% c(1, 10, 50, 100, 365)) %>%
  # filter(lubridate::mday(date_of_forecast) == 1) %>%
  # filter(lubridate::yday(date_of_forecast) == 1 | 
  #          lubridate:: yday(date_of_forecast) == 182 | 
  #          lubridate::yday(date_of_forecast) == 365) %>%
  # filter(date_of_forecast == '2017-01-15' | 
  #          date_of_forecast == '2017-09-01' |
  #          date_of_forecast == '2017-12-01' |
  #          date_of_forecast == '2017-06-01') %>%
  mutate_at(c("fit", "upr", "lwr"),
            ~ exp(.))

# plot
game_data %>%
  ggplot(., aes(x=date,
                y=exp(users_rated)))+
  geom_ribbon(data=selected_days,
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
        #        y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_line(data=selected_days,
              alpha=0.8,
              color = "black",
              aes(x=date,
                  group = date_of_forecast,
                  y=fit))+
  geom_line(color = "red", lwd=1.1)+
  theme_phil()+
  scale_fill_grey()+
 # geom_vline(xintercept = selected_days$date_of_forecast,
  #           linetype = 'dotted')+
  theme(legend.title = element_text())+
  guides(fill = guide_legend(title = "Date of Forecast",
                             title.position = 'top'))+
  guides(fill ="none")+
  labs(caption = paste(paste("Game ID: ",selected_days[1,]$game_id),
                       paste("Game:", game_data[1,]$name),
                       sep="\n"))+
  ylab("Users Rated")+
  xlab("")+
  coord_cartesian(ylim = c(0, NA))+
  facet_wrap(factor(date_of_forecast)~.)

```

It looks like the game got into the hands of backers right at the end of 2019, at which point it started to really take off. Once we started seeing some of that, the forecasts adjusted pretty dramatically. 

This is going to be a difficult one absent information about a game's actual release, which is notoriously difficult on boardgamegeek.

We can open up the data we have until present to see where this game sits, using our forecast from 2019-08-01.

```{r examine this game from our forecast}

games_ts %>%
  filter(game_id == miss_ids[2]) %>%
  ggplot(., aes(x=date, y=users_rated))+
  geom_ribbon(data = game_forecasts %>% 
                filter(date_of_forecast == '2019-08-01'),
              aes(x= date,
                  ymin = lwr,
                  ymax = upr),
              alpha = 0.5)+
  geom_line(col = "red")+
  geom_line(data = game_forecasts %>% 
                filter(date_of_forecast == '2019-08-01'),
              aes(x= date,
                  y = fit),
              col = 'black',
              alpha = 0.8)+
  theme_phil()+
  labs(caption = paste(paste("Game ID: ",selected_days[1,]$game_id),
                       paste("Game:", game_data[1,]$name),
                       sep="\n"))

```

Once we start to see users ratings come in, the model starts to forecast where we'd expect it to be a year out.

### Overestimating User Ratings

```{r look at a miss 2}

# get game
game_data = baked_started_valid %>%
    filter(game_id %in% c(miss_ids[1])) 
  
# get predictions
game_forecasts = pred_valid %>%
    filter(game_id %in% c(miss_ids[1])) %>%
  select(date_of_forecast,
         date,
         days_since_start,
         game_id,
         users_rated,
         horizon,
         fit,
         lwr,
         upr) %>%
  arrange(game_id, date_of_forecast, horizon)  %>%
  left_join(.,  games_ts %>%
              mutate(users_rated = log(users_rated)) %>%
              select(date, game_id, users_rated) %>%
              rename(actual = users_rated),
           by = c("game_id", "date")) %>%
  mutate(days_since_forecast = as.numeric(date - date_of_forecast)) %>%
  mutate_at(c("fit", "lwr", "upr","actual"),
            ~ round(exp(.), 0)) %>%
  filter(game_id %in% c(miss_ids[1]))
  
# filter to specified days
selected_days = pred_valid %>%
  filter(game_id %in% game_data$game_id) %>%
  select(date, date_of_forecast, game_id, users_rated, horizon, fit, lwr, upr, users_rated, days_since_start) %>%
  arrange(date_of_forecast, date, horizon) %>%
  filter(days_since_start %in% c(1, 10, 50, 100, 365)) %>%
  # filter(lubridate::mday(date_of_forecast) == 1) %>%
  # filter(lubridate::yday(date_of_forecast) == 1 | 
  #          lubridate:: yday(date_of_forecast) == 182 | 
  #          lubridate::yday(date_of_forecast) == 365) %>%
  # filter(date_of_forecast == '2017-01-15' | 
  #          date_of_forecast == '2017-09-01' |
  #          date_of_forecast == '2017-12-01' |
  #          date_of_forecast == '2017-06-01') %>%
  mutate_at(c("fit", "upr", "lwr"),
            ~ exp(.))

# plot real game
game_data %>%
  ggplot(., aes(x=date,
                y=exp(users_rated)))+
  geom_ribbon(data=selected_days,
              alpha=0.5,
              aes(x=date,
                  fill = factor(date_of_forecast),
                  group = date_of_forecast,
        #        y=fit,
                ymin = lwr,
                ymax = upr))+
  geom_line(data=selected_days,
              alpha=0.8,
              color = "black",
              aes(x=date,
                  group = date_of_forecast,
                  y=fit))+
  geom_line(color = "red", lwd=1.1)+
  theme_phil()+
  scale_fill_grey()+
 # geom_vline(xintercept = selected_days$date_of_forecast,
  #           linetype = 'dotted')+
  theme(legend.title = element_text())+
  guides(fill = guide_legend(title = "Date of Forecast",
                             title.position = 'top'))+
  guides(fill ="none")+
  labs(caption = paste(paste("Game ID: ",selected_days[1,]$game_id),
                       paste("Game:", game_data[1,]$name),
                       sep="\n"))+
  ylab("Users Rated")+
  xlab("")+
  coord_cartesian(ylim = c(0, NA))+
  facet_wrap(factor(date_of_forecast)~.)

```

This isn't that big of a miss all things considered, but the model thought there would be growth based on the fact that it had a really high bgg_average, about 9.5. From looking at some threads on BGG, it would seem this is due to a lot of people inputting 10s for this game.

```{r look at miss 2 ratings}

games_ts %>%
  filter(game_id == 236332) %>%
  arrange(date)

```
Remove for next section.

```{r rm and prep for next section, warning=F}

rm(baked_started_train,
   baked_started_valid,
   games_started_train,
   games_started_valid,
   real_game,
   pred_valid,
   sample_game,
   sample_games,
   selected_days,
   one_day,
   samp_forecast,
   games_started)

```


## Forecasting 2020 and 2021

Okay, let's now put this all together. Let's bind together and start forecasting games from 2020 and 2021.

```{r bind and bake}

end_publish_year = 2020

# get games that started
games_started<-games_ts %>%
        ungroup() %>%
        mutate(minimum_date = min(date)) %>%
        group_by(game_id) %>%
        mutate(start_date = min(date)) %>%
        ungroup() %>%
        filter(start_date > minimum_date) %>%
        filter(date == start_date) %>%
        left_join(., games_info %>%
                          select(game_id, yearpublished),
                  by = c("game_id")) %>%
        select(game_id, start_date, yearpublished) %>%
        filter(yearpublished > 2015)

# number of games released per year
games_started %>%
        as.data.frame() %>%
        group_by(yearpublished) %>%
        summarize(games_released = n_distinct(game_id))

# filter to only games started
games_started_train<-bind_rows(games_tsibble_train) %>%
  filter(game_id %in% games_started$game_id) %>%
  left_join(., games_started %>%
              as_tibble() %>%
              select(-yearpublished),
            by = c("game_id")) %>%
  left_join(., games_info,
            by = c("game_id")) %>%
  filter(yearpublished < end_publish_year) %>%
  filter(year(start_date) < end_publish_year) %>%
  as_tibble()

# # games from 2020
# games_started_test<-bind_rows(games_tsibble_train,
#                                games_tsibble_test) %>%
#   filter(game_id %in% games_started$game_id) %>%
#   left_join(., games_started %>%
#               as_tibble() %>%
#               select(-date, -yearpublished),
#             by = c("game_id")) %>%
#   left_join(., games_info,
#             by = c("game_id")) %>%
#   filter(yearpublished == end_publish_year) %>%
#   filter(year(start_date) == end_publish_year) %>%
#   as_tibble()


# games_started_train=games_tsibble_train %>%
#   filter(game_id %in% games_started$game_id) %>%
#   left_join(., games_started %>%
#               as_tibble() %>%
#               select(-date, -yearpublished),
#             by = c("game_id")) %>%
#   left_join(., games_info,
#             by = c("game_id")) %>%
#   filter(yearpublished < end_publish_year) %>%
#   filter(year(start_date) < end_publish_year) %>%
#   as_tibble()

```

Apply our recipe.

```{r bake recipe on training set}

baked_started_train <- recipe_ts %>%
  prep(games_started_train, strings_as_factor = F) %>%
  bake(new_data = NULL)

```

Now train models.

Use forecasting function to prep the data

```{r use forecasting function, warning=F, message=F}

horizons =c(30, 90, 180, 365, 720)

## use function at each horizon length
forecasting_horizon_train<-foreach(i=1:length(horizons), .combine = bind_rows) %do% {
  
  prep_ts_direct_func(data = baked_started_train,
                    horizon_length = horizons[i],
                    lag_vars = time_vars)
  
}

forecasting_horizon_train

```

Fit the models

```{r fit models as a test, warning=F}

# train models
model_results<- forecasting_horizon_train %>%
  mutate(outcome = "users_rated") %>%
  select(horizon, outcome, data) %>%
  mutate(lm = map(data, ~ lm_cv(df = .x,
                                        outcome_var = "users_rated")))

# glance
model_glanced = model_results %>%
  mutate(glanced = map(lm, ~ .x %$%
                        finalModel %>%
                         glance(.))) %>%
  select(horizon, glanced) %>% 
  unnest() %>%
  mutate_if(is.numeric, round, 3)

model_glanced

# tidied
model_tidied = model_results %>%
  mutate(tidied = map(lm, ~ .x$finalModel %>%
                        tidy(se="robust", conf.int=T))) %>%
  select(horizon, tidied) %>%
  unnest() %>%
  mutate_if(is.numeric, round, 3) 

model_tidied

  # filter(term != '(Intercept)') %>%
  # mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>% 
  # filter(term == 'users_rated')
# # # look at coefs
# tidy(model_results[2,]$lm_interactions[[1]]$finalModel) %>%
#   mutate_if(is.numeric, round, 3)

```

Now use these models to predict games released in 2020 and 2021.

```{r bake recipe on combined}

games_tsibble_test<- games_ts_test %>%
        filter(!are_duplicated(games_ts_test, index=date, key=game_id)) %>% # remove duplicates
        filter(game_id %in% games_info$game_id) %>%  # filter to only games that we have active records on
        as_tsibble(index = date,
                   key = game_id) %>%
        tsibble::fill_gaps(., .full=FALSE) %>%
        mutate_at(c("game_release_year", 
                    "bgg_rank",
                    "bgg_average",
                    "bayes_average",
                    "users_rated"),
                  repeat.before)

# filter to only games started
games_started_test<-bind_rows(games_tsibble_test) %>%
  filter(game_id %in% games_started$game_id) %>%
  left_join(., games_started %>%
              as_tibble() %>%
              select(-yearpublished),
            by = c("game_id")) %>%
  left_join(., games_info,
            by = c("game_id")) %>%
  filter(year(start_date) >= 2020) %>%
  filter(yearpublished < 2022) %>%
  # filter(yearpublished  end_publish_year) %>%
  # filter(year(start_date) == end_publish_year) %>%
  as_tibble()

# bake
baked_started_test<-recipe_ts %>%
  prep(games_started_train, strings_as_factor = F) %>%
  bake(games_started_test)

```

Now predict the test set.

```{r predict test set, warning=F}

# use teh direct forecasting models
pred_test<- model_results %>%
  select(horizon, lm) %>%
  mutate(horizon = as.numeric(gsub(" days", "", horizon))) %>%
  mutate(pred = map2(lm,
                     horizon,
                     ~.x %$%
                      finalModel %>%
                      predict(., newdata = baked_started_test, level = .9, interval = "prediction") %>%
                      as_tibble() %>%
                       cbind.data.frame(., baked_started_test %>%
                                          select(date, game_id, start_date, days_since_start)) %>%
                       mutate(date_of_forecast = date,
                              date = date+.y))) %>%
  select(horizon, pred) %>%
  unnest() %>%
  select(date_of_forecast, date, start_date, game_id, days_since_start, horizon, fit, lwr, upr)

```

Now see how we did.

```{r evalute results on test set}

pred_test_and_actual = pred_test %>%
  left_join(., games_ts %>%
              select(date, game_id, users_rated) %>%
              mutate(users_rated = log(users_rated)) %>%
              rename(actual = users_rated),
            by = c("date", "game_id")) %>%
  left_join(., games_info,
            by = c("game_id"))

```


Assess

```{r plot resutlts, warning=F}

pred_test_and_actual %>%
  filter(days_since_start <= 365) %>%
  filter(horizon != 720) %>%
  group_by(horizon, days_since_start) %>%
  reg_metrics(truth = actual,
                  estimate = fit,
                  na_rm = T) %>%
  ggplot(., aes(x=days_since_start,
                y=.estimate,
                color = factor(horizon)))+
  geom_line()+
  facet_wrap(.metric~.,
             scales = "free_y")+
  theme_phil()+
  scale_color_viridis_d()+
  geom_vline(xintercept = c(50,100),
             linetype = 'dashed')+
  xlab("Days Since Game Entered")+
  ylab(".estimate")+
  theme(legend.title = element_text())+
  guides(color = guide_legend(title = "Forecasting Horizon",
                              title.position = "top"))+
  labs(caption = str_wrap("Assessing forecasted user ratings for games that entered the database in 2020 and 2021. Vertical lines indicate 50 and 100 day marks."))


```


Let's plot a game published in 2020 and see what the model thought.

```{r sample games in 2020 1, fig.height=3}

# get game data
game_data = games_ts %>%
  left_join(., active_games,
            by = "game_id") %>%
  filter(game_id == samp_id)


# get game pred
samp = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(lubridate::mday(date_of_forecast) == 1) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

# combine 
game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))


samp2 = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(days_since_start == 100) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp2,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp2,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))

samp3 = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(days_since_start == max(days_since_start)) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp3,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp3,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))

```

```{r sample games in 2020 2, fig.height=3}

samp_id = 311193

# get game data
game_data = games_ts %>%
  left_join(., active_games,
            by = "game_id") %>%
  filter(game_id == samp_id)


# get game pred
samp = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(lubridate::mday(date_of_forecast) == 1) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

# combine 
game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))


samp2 = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(days_since_start == 100) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp2,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp2,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))

samp3 = pred_test_and_actual %>%
  filter(game_id == samp_id) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ exp(.)) %>%
  select(date_of_forecast, 
         date,
         start_date,
         game_id,
         days_since_start,
         horizon,
         fit,
         lwr,
         upr,
         actual) %>%
  filter(days_since_start == max(days_since_start)) %>%
  mutate(date_of_forecast = paste("Forecast From:", date_of_forecast))

game_data %>%
  ggplot(., aes(x=date))+
  geom_line(aes(y=users_rated),
            color = 'red')+
  geom_line(data = samp3,
              alpha=0.7,
            color = 'black',
              aes(x=date,
                  y = fit))+
  geom_ribbon(data = samp3,
              alpha=0.7,
              aes(x=date,
                  ymin = lwr,
                  ymax = upr))+
  theme_phil()+
  facet_wrap(date_of_forecast ~.,
             scales = "free_y")+
  ylab("BGG User Ratings")+
  xlab("Date")+
  labs(caption = paste(paste("Game: ", game_data$name[1]),
                       paste("Game ID:", game_data$game_id[1]),
                       sep = "\n"))
      
```

What games are forecasted to be the most popular by the end of 2022?


```{r top from forecasted}

col_func<- function(x) {
  
  breaks<-quantile(x, probs = seq(0, 1, by=.05), na.rm=T) %>% as.vector()
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

pred_test_and_actual %>%
  group_by(game_id) %>%
  mutate(max_days = max(days_since_start)) %>%
  ungroup() %>%
  filter(days_since_start == max_days) %>%
  ungroup() %>%
 # filter(days_since_start == 100) %>%
 # filter(year(date) < 2023) %>%
  arrange(game_id, horizon) %>%
  mutate_at(c("fit", "lwr", "upr", "actual"),
            ~ round(exp(.)), 0) %>%
  select(date_of_forecast, start_date, date, game_id, name, days_since_start, horizon, fit, lwr, upr, actual) %>%
  arrange(desc(fit)) %>%
  mutate(start_year = year(start_date)) %>%
  filter(start_year == 2021) %>%
  filter(horizon == 365) %>%
  select(date_of_forecast, date, start_year, game_id, name, days_since_start, fit, lwr, upr) %>%
  left_join(., games_ts %>%
              filter(date == max(date)) %>%
              rename(date_of_forecast = date) %>%
              select(date_of_forecast, game_id, users_rated)) %>%
  select(date_of_forecast, game_id, name, date, users_rated,  days_since_start, fit, lwr, upr) %>%
  select(-lwr, -upr) %>%
  select(-date_of_forecast) %>%
  mutate(game_id = as.character(game_id)) %>%
  rename(forecasted = fit,
         current = users_rated) %>%
 # filter(current > 500) %>%
  mutate(diff = forecasted - current) %>%
  flextable() %>%
  flextable::autofit() 

# %>%
#   autofit() %>%
#         bg(j = c('diff'),
#            bg = col_func)



```

