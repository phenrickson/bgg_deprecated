---
title: "Analyzing Individual BGG Users"
author: Phil Henrickson
date: "`r Sys.Date()`"
output: 
  html_document:
        toc: true
        toc_depth: 3
params:
  username: "mrbananagrabber"
  end_training_year: 2020
---

```{r load and set packages, echo=F, warning=F, message=F,  results = 'hide'}

knitr::opts_chunk$set(echo = F,
                      dev="png",
                      fig.width = 8,
                      fig.height = 6)

options(knitr.duplicate.label = "allow")

options(scipen=999)

source("load_packages.R")
source("theme_phil.R")
library(webshot2)
library(magick)
library(flextable)
library(bggAnalytics)
library(tidymodels)
library(workflows)
library(rsample)

set_flextable_defaults(theme_fun = theme_booktabs,
                       font.color = "black",
  padding.bottom = 6, 
  padding.top = 6,
  padding.left = 6,
  padding.right = 6,
  background.color = "white")

```

Load previously queried training and test data from the local layer.

```{r load previously stored data, warning=F, mesage=F, echo=F}

#load("/Users/Phil/OneDrive - AE Business Solutions/Documents/board_game_projects/bgg/games_train.Rdata")
#load("/Users/Phil/OneDrive - AE Business Solutions/Documents/board_game_projects/bgg/games_test.Rdata")
# source("functions/get_models_and_training_data.R")
# bar= get_models_and_training_data()

all_files = list.files(here::here("local"))
        
most_recent_games = all_files[grepl("games_datasets", all_files)] %>%
          as_tibble() %>%
          separate(value, c("name1", "name2", "date", "file"), sep = "([._])",
                   extra = "merge",
                   fill = "left") %>%
          unite(name, name1:name2) %>%
          mutate(date = as.Date(date)) %>%
          filter(date == max(date)) %>%
          unite(path, name:file) %>%
          mutate(path = gsub("_Rdata", ".Rdata", path)) %>%
          pull(path)

games_datasets = readr::read_rds(here::here("local", most_recent_games))

most_recent_date = as.Date(games_datasets$train$timestamp[1])

my_caption = list(labs(caption = paste(paste("Data from boardgamegeek.com as of", most_recent_date),
                        paste("Data and analysis at github.com/phenrickson/bgg"), sep="\n")))

```

Set function for displaying probabilities

```{r functions, echo = F, warning=F, message=F}

col_func<- function(x) {
  
  breaks<-seq(0, 1, .01)
  
#  breaks = weight_deciles
  colorRamp=colorRampPalette(c("white", "deepskyblue1"))
  col_palette <- colorRamp(length(breaks))
  mycut <- cut(x, 
    breaks = breaks,
    include.lowest = TRUE, 
    right=T,
    label = FALSE)
  col_palette[mycut]
  
}

# get user collection
get_user_collection = function(username) {
        
        # load bgg analytics
        library(bggAnalytics)
        
        # load function for grabbing collections
        source("functions/get_collection.R")
        
        # load collection
        get_collection(username) %>%
                        as_tibble()
        
}

# combine training data with collection data and bake
bake_user_collection = function(data,
                                year_split,
                                collection_data) {
  
    # split datasets
    train_data = data %>%
      filter(yearpublished < year_split)
    
    test_data = data %>%
      filter(yearpublished >= year_split)
        
        # combine collection data with train data
        training_and_collection_data = train_data %>%
                left_join(., 
                          collection_data %>%
                                  mutate(played = case_when(own == 1 | prevowned == 1| !(is.na(rating)) ~ 1,
                                                                 TRUE ~ 0)) %>%
                                  mutate(have_owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                                                TRUE ~ 0)) %>%
                                  select(game_id, own, have_owned, played, rating, username) %>%
                                  pivot_wider(names_from = c("username"),
                                              values_from = c("own", "played", "rating"),
                                              values_fn = max,
                                              id_cols = game_id) %>%
                                  mutate_at(vars(starts_with("have_owned_")),
                                            ~ replace_na(., 0)) %>%
                                  mutate_at(vars(starts_with("own_")),
                                            ~ replace_na(., 0)),
                          by = c("game_id"))
        
        # create recipe 
        recipe<- recipe(~ .,
                        x = training_and_collection_data) %>%
                update_role(all_numeric(),
                            new_role = "predictor") %>%
                update_role(timestamp,
                            usersrated,
                            game_id,
                            name,
                            average,
                            baverage,
                            new_role = "id") %>%
                update_role(starts_with("have_owned"),
                            starts_with("played"),
                            starts_with("own_"),
                            starts_with("rating_"),
                            new_role = "id") %>%
                step_filter(!is.na(yearpublished)) %>%
                step_filter(
                        cat_collectible_components !=1 &
                                cat_expansion_for_basegame != 1) %>% # remove specific categories that count expansions
          #      step_filter(yearpublished > 1900) %>%
                step_mutate(published_prior_1900 = case_when(yearpublished<1900 ~ 1,
                                                             TRUE ~ 0)) %>%
                step_mutate(yearpublished = case_when(yearpublished <= 1900 ~ 1900,
                                                      TRUE ~ as.numeric(yearpublished))) %>% # truncate yearpublished
                # step_mutate(years_since_published = as.numeric(year(Sys.Date()))-yearpublished) %>%
                step_impute_median(avgweight,
                                   minplayers,
                                   maxplayers,
                                   playingtime,
                                   minage) %>% # medianimpute numeric predictors
                step_mutate(minplayers = case_when(minplayers < 1 ~ 1,
                                                   minplayers > 10 ~ 10,
                                                   TRUE ~ minplayers),
                            maxplayers = case_when(maxplayers < 1 ~ minplayers,
                                                   maxplayers > 20 ~ 20,
                                                   TRUE ~ maxplayers)) %>% # truncate player range
                step_mutate(time_per_player = playingtime/ maxplayers) %>% # make time per player variable
                step_mutate_at(starts_with("cat_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("mech_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("des_"),
                               fn = ~ replace_na(., 0)) %>%
               step_mutate_at(starts_with("art_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("pub_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("own_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("have_owned_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate_at(starts_with("played_"),
                               fn = ~ replace_na(., 0)) %>%
                step_mutate(number_mechanics = rowSums(across(starts_with("mech_"))),
                            number_categories = rowSums(across(starts_with("cat_")))) %>%
              #              number_artists = rowSums(across(starts_with("art_")))) %>%
                step_log(playingtime,
                         time_per_player,
                         offset = 1) %>%
                step_zv(all_predictors()) %>%
                step_nzv(all_predictors(),
                         freq_cut = 150/1)
        
        # bake training set
        train_out = recipe %>%
                prep(training_and_collection_data, strings_as_factor =F) %>%
                bake(new_data = NULL)
        
        # combine test with collection data
        test_and_collection_data = test_data %>%
                left_join(., 
                          collection_data %>%
                                  mutate(played = case_when(own == 1 | prevowned == 1| !(is.na(rating)) ~ 1,
                                                                 TRUE ~ 0)) %>%
                                  mutate(have_owned = case_when(own == 1 | prevowned == 1 ~ 1,
                                                                TRUE ~ 0)) %>%
                                  select(game_id, own, have_owned, played, rating, username) %>%
                                  pivot_wider(names_from = c("username"),
                                              values_from = c("own", "played", "rating"),
                                              values_fn = max,
                                              id_cols = game_id) %>%
                                  mutate_at(vars(starts_with("have_owned_")),
                                            ~ replace_na(., 0)) %>%
                                  mutate_at(vars(starts_with("own_")),
                                            ~ replace_na(., 0)),
                          by = c("game_id"))
        
        # bake test set
        test_out = recipe %>%
                prep(training_and_collection_data, strings_as_factor =F) %>%
                bake(new_data = test_and_collection_data)
        
        # return baked training set
        out = list("training" = train_out,
                   "test" = test_out)
        
        return(out)
        
}

# model off baked data
model_user_collection = function(baked_data) {
        
        # get training set
        baked_train = baked_data$training
        
        # get all vars
        vars=names(baked_train %>%
                           select(-starts_with("rating_"),
                                  -starts_with("own_"),
                                  -starts_with("played"),
                                  -starts_with("have_owned")))
        
        # melt
        melted_baked_train <- baked_train %>%
                melt(., id.vars = vars) %>%
                rename(outcome = value) %>%
                mutate(outcome_type = case_when(grepl("have_owned_", variable) ~ 'have_owned',
                                                grepl("own_", variable) ~ "own",
                                                grepl("played", variable) ~ "played",
                                                grepl("rating_", variable) ~ 'rating')) %>%
                mutate(outcome = case_when((outcome_type == 'own' | outcome_type == 'have_owned') & is.na(outcome) ~ 0,
                                           TRUE ~ outcome)) %>%
                filter(!is.na(outcome)) %>%
                mutate(username = gsub("played_","", gsub("own_", "", gsub("rating_", "", gsub("have_owned_", "", variable))))) %>%
                select(username, outcome_type, outcome, variable, everything()) %>%
                nest(-username, -outcome_type, -variable)
        
        
        ### stuff needed for modeling
        # penalized linear regression
        glmnet_reg_mod<- 
                linear_reg(penalty = tune::tune(),
                           mixture = 0.5) %>%
                set_engine("glmnet")
        
        # penalized logistic regression
        glmnet_class_mod<- 
                logistic_reg(penalty = tune::tune(),
                             mixture = 0.5) %>%
                set_engine("glmnet")
        
        # specify grid for tuning
        glmnet_grid <- tibble(penalty = 10^seq(-4, -0.5, 
                                               length.out = 30))
        
        # specify regression metrics
        reg_metrics<-metric_set(yardstick::rmse,
                                yardstick::rsq,
                                yardstick::mae,
                                yardstick::mape)
        
        # specify regression metrics
        class_metrics<-metric_set(yardstick::roc_auc,
                                  yardstick::mn_log_loss)
        
        ### stuff for running workflows
        
        # function for standard recipe
        recipe_function = function(df, setting) {
                
                # change to factor if classification
                if (setting == 'classification') {df$outcome = as.factor(df$outcome)}
                else if (setting == 'regression') {df$outcome = df$outcome} 
                else {'select classification or regression'}
                
                norm_recipe = recipe_train <-
                        recipe(outcome ~ ., data = df) %>%
                        update_role(timestamp,
                                    usersrated,
                                    game_id,
                                    name,
                                    average,
                                    baverage,
                                    new_role = "id") %>%
                        step_zv(all_predictors()) %>%
                        step_corr(all_predictors(),
                                  threshold = 0.95) 
        }
        
        # function for normalized recipe
        norm_recipe_function = function(df, setting) {
                
                # change to factor if classification
                if (setting == 'classification') {df$outcome = as.factor(df$outcome)}
                else if (setting == 'regression') {df$outcome = df$outcome} 
                else {'select classification or regression'}
                
                norm_recipe = recipe_train <-
                        recipe(outcome ~ ., data = df) %>%
                        update_role(timestamp,
                                    usersrated,
                                    game_id,
                                    name,
                                    average,
                                    baverage,
                                    new_role = "id") %>%
                        step_zv(all_predictors()) %>%
                        step_corr(all_predictors(),
                                  threshold = 0.95) %>%
                        step_normalize(all_predictors())
                
        }
        
        # function for fitting workflow using a selected model and recipe
        fit_workflow_function <- function(df, input_model, input_recipe, metrics) {
                
                # change to factor if classification
                if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
                else if (metrics == 'regression') {df$outcome = df$outcome} 
                else {'select classification or regression'}
                
                # fit model
                fit_wf <-
                        workflow() %>%
                        add_model(input_model) %>%
                        add_recipe(input_recipe) %>%
                        fit(df)
                
                
        }
        
        # function for tuning a workflow over folds
        tune_workflow_function <- function(df, input_model, input_recipe, input_grid, metrics) {
                
                # change to factor if classification
                if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
                else if (metrics == 'regression') {df$outcome = df$outcome} 
                else {'select classification or regression'}
                
                # create folds
                set.seed(1999)
                train_folds = vfold_cv(df,
                                       strata = outcome,
                                       v = 5,
                                       repeats = 1)
                
                # if regression then
                if (metrics == "regression") {
                        fit_wf <-
                                workflow() %>%
                                add_model(input_model) %>%
                                add_recipe(input_recipe) %>%
                                tune_grid(train_folds,
                                          grid = input_grid,
                                          control = control_grid(save_pred = TRUE),
                                          metrics = reg_metrics)
                } else if (metrics == "classification") {
                        fit_wf <-
                                workflow() %>%
                                add_model(input_model) %>%
                                add_recipe(input_recipe) %>%
                                tune_grid(train_folds,
                                          grid = input_grid,
                                          control = control_grid(save_pred = TRUE),
                                          metrics = class_metrics)
                } else {"select regression or classification"}
                
        }
        
        
        ## for finalizing workflow
        # function to finalize workflow using tune results
        finalize_workflow_function<- function(df, input_model, input_recipe, tune_results, metrics) {
                
                # change to factor if classification
                if (metrics == 'classification') {df$outcome = as.factor(df$outcome)}
                else if (metrics == 'regression') {df$outcome = df$outcome} 
                else {'select classification or regression'}
                
                #fit workflow on train data
                fit_wf <-
                        workflow() %>%
                        add_model(input_model) %>%
                        add_recipe(input_recipe)
                
                # finalize workflow
                final_wf <-
                        fit_wf %>%
                        finalize_workflow(tune_results) %>%
                        fit(df)
                
        }
        
        # ### fitting models
        # set.seed(1999)
        # # ratings
        # ratings_models = melted_baked_train %>%
        #         filter(outcome_type == 'rating') %>%
        #         mutate(glmnet_tune = map(data,
        #                                  ~ tune_workflow_function(df = .x,
        #                                                           input_model = glmnet_reg_mod,
        #                                                           input_grid = glmnet_grid,
        #                                                           input_recipe = norm_recipe_function(.x, setting = 'regression'),
        #                                                           metrics = 'regression'))) %>%
        #         mutate(glmnet_best = map(glmnet_tune, ~ .x %>% show_best(n=1))) %>%
        #         mutate(glmnet_results = map2(.x = glmnet_tune,
        #                                      .y = glmnet_best,
        #                                      ~ .x %>% collect_predictions(parameters = .y))) %>%
        #         mutate(glmnet_fit = map2(.x=data,
        #                                  .y = glmnet_best,
        #                                  ~ finalize_workflow_function(df = .x,
        #                                                               input_model = glmnet_reg_mod,
        #                                                               tune_results = .y,
        #                                                               input_recipe = norm_recipe_function(.x, setting = 'regression'),
        #                                                               metrics = "regression"))) 
        
        # set.seed(1999)
        # # have owned
        # have_owned_models = melted_baked_train %>%
        #         filter(outcome_type == 'have_owned') %>%
        #         mutate(glmnet_tune = map(data,
        #                                  ~ tune_workflow_function(df = .x,
        #                                                           input_model = glmnet_class_mod,
        #                                                           input_grid = glmnet_grid,
        #                                                           input_recipe = norm_recipe_function(.x, setting = 'classification'),
        #                                                           metrics = 'classification'))) %>%
        #         mutate(glmnet_best = map(glmnet_tune, ~ .x %>% show_best(n=1))) %>%
        #         mutate(glmnet_results = map2(.x = glmnet_tune,
        #                                      .y = glmnet_best,
        #                                      ~ .x %>% collect_predictions(parameters = .y) %>%
        #                                              arrange(.row))) %>%
        #         mutate(glmnet_fit = map2(.x=data,
        #                                  .y = glmnet_best,
        #                                  ~ finalize_workflow_function(df = .x,
        #                                                               input_model = glmnet_class_mod,
        #                                                               tune_results = .y,
        #                                                               input_recipe = norm_recipe_function(.x, setting = 'classification'),
        #                                                               metrics = "classification"))) 
        # 
        set.seed(1999)
        # have played
        played_models = melted_baked_train %>%
                filter(outcome_type == 'played') %>%
                mutate(glmnet_tune = map(data,
                                         ~ tune_workflow_function(df = .x,
                                                                  input_model = glmnet_class_mod,
                                                                  input_grid = glmnet_grid,
                                                                  input_recipe = norm_recipe_function(.x, setting = 'classification'),
                                                                  metrics = 'classification'))) %>%
                mutate(glmnet_best = map(glmnet_tune, ~ .x %>% show_best(n=1))) %>%
                mutate(glmnet_results = map2(.x = glmnet_tune,
                                             .y = glmnet_best,
                                             ~ .x %>% collect_predictions(parameters = .y) %>%
                                                     arrange(.row))) %>%
                mutate(glmnet_fit = map2(.x=data,
                                         .y = glmnet_best,
                                         ~ finalize_workflow_function(df = .x,
                                                                      input_model = glmnet_class_mod,
                                                                      tune_results = .y,
                                                                      input_recipe = norm_recipe_function(.x, setting = 'classification'),
                                                                      metrics = "classification"))) 
        set.seed(1999)
        # own
        own_models = melted_baked_train %>%
                filter(outcome_type == 'own') %>%
                mutate(glmnet_tune = map(data,
                                         ~ tune_workflow_function(df = .x,
                                                                  input_model = glmnet_class_mod,
                                                                  input_grid = glmnet_grid,
                                                                  input_recipe = norm_recipe_function(.x, setting = 'classification'),
                                                                  metrics = 'classification'))) %>%
                mutate(glmnet_best = map(glmnet_tune, ~ .x %>% show_best(n=1))) %>%
                mutate(glmnet_results = map2(.x = glmnet_tune,
                                             .y = glmnet_best,
                                             ~ .x %>% collect_predictions(parameters = .y) %>%
                                                     arrange(.row))) %>%
                mutate(glmnet_fit = map2(.x=data,
                                         .y = glmnet_best,
                                         ~ finalize_workflow_function(df = .x,
                                                                      input_model = glmnet_class_mod,
                                                                      tune_results = .y,
                                                                      input_recipe = norm_recipe_function(.x, setting = 'classification'),
                                                                      metrics = "classification"))) 
        
        ### combine all models
        all_models = bind_rows(
                # ratings_models,
            #    have_owned_models,
                played_models,
                own_models)
        
        return(all_models)
        
}

# get coefficients
model_coefs_user = function(models, effect_size) {
        
        # get coefs
        training_coefs = models %>%
                mutate(glmnet_coefs = map(glmnet_fit, ~ .x %>% extract_fit_parsnip() %>%
                                                  tidy())) %>%
                select(username, outcome_type, glmnet_coefs)
        
      source("functions/rename_func.R")
        
        # function for plotting
        plot_coef_function <- function(coefs,
                                       effect_size) {
                # for me
                coefs %>%
                        unnest() %>%
                        filter(term != '(Intercept)') %>%
                        mutate(term = rename_func(term)) %>%
                        filter(abs(estimate) > effect_size ) %>%
                        ggplot(., aes(x= reorder(term, estimate),
                                      shape = outcome_type,
                                      color = outcome_type,
                                      y = estimate))+
                        geom_point(alpha=0.6)+
                        coord_flip()+
                        facet_wrap(username ~.)+
                        #scale_color_grey(start = 0.2, end = 0.6)+
                        scale_color_colorblind()+
                        theme_phil()+
                        theme(axis.text.y = element_text(size=rel(0.75)))+
                        geom_hline(yintercept = 0,
                                   linetype = 'dotted')+
                        xlab("Feature")+
                        ylab("Estimated Effect on Outcome")+
                        labs(title = "What Predicts a User's Collection?",
                             subtitle = str_wrap(paste("Coefficients from penalized logistic regression models for a user's BGG Collection. Predictors centered and scaled. Models trained on all games published before", params$end_training_year), 90))+
                        theme(panel.grid.minor = element_blank(),
                              panel.grid.major = element_blank())+
                        my_caption
                
        }
        
        # plot
        return(plot_coef_function(training_coefs,
                                  effect_size))
        
}

# predict test set
predict_test_user_collection = function(user_models,
                                        baked_data) {
                                        # predict off baked test data
                                        
                                        test_preds = user_models %>%
                                                filter(outcome_type != 'rating') %>%
                                                select(username, outcome_type, glmnet_fit) %>%
                                                #select(username, outcome_type, glmnet_fit, xgbTree_fit) %>%
                                                mutate(glmnet_preds = map(glmnet_fit,
                                                                          ~ .x %>%
                                                                                  predict(baked_test, type = 'prob') %>%
                                                                                  rename(glmnet = .pred_1) %>%
                                                                                  select(glmnet) %>%
                                                                                  mutate(.row = row_number())))%>%
                                                # mutate(xgbTree_preds = map(xgbTree_fit,
                                                #                            ~ .x %>%
                                                #                              predict(baked_test, type = 'prob') %>%
                                                #                              rename(xgbTree = .pred_1) %>%
                                                #                              select(xgbTree) %>%
                                                #                              mutate(.row = row_number()))) %>%
                                                select(username, outcome_type, glmnet_preds) %>%
                                                # select(username, outcome_type, glmnet_preds, xgbTree_preds) %>%
                                                unnest() %>%
                                                select(-one_of(".row1")) %>%
                                                left_join(., baked_data$test %>%
                                                                  mutate(.row = row_number()),
                                                          by = ".row") %>%
                                                mutate(user_variable = paste(outcome_type, username, sep="_"))
}

# all in one go
analyse_user = function(username,
                        data, 
                        year_split) {
        
        # get collection
        user_collection = get_user_collection(username)
        
        # bake with recipe and training
        baked_user_collection = bake_user_collection(data = data,
                                                     year_split = year_split,
                                                     collection_data = user_collection)
        
        # train models
        models_user = model_user_collection(baked_user_collection)
        
        # get coefs
        coefs_user=model_coefs_user(models_user,
                         effect_size = 0.025)
        
        # examine oos preds
        oos_preds = models_user %>%
                select(username, outcome_type, data, glmnet_results) %>% 
                unnest() %>%
                arrange(.row) %>%
                select(username, yearpublished, outcome_type, game_id, name, outcome, .pred_1) %>%
                rename(pred = .pred_1,
                       actual = outcome) %>%
                pivot_wider(., names_from = c("outcome_type"),
                            values_from = c("pred", "actual")) %>%
                mutate_if(is.numeric, round, 2) %>%
                arrange(desc(pred_own)) %>%
                mutate(game_id = as.character(game_id),
                       yearpublished = as.character(yearpublished)) %>%
                select(username, yearpublished, game_id, name, everything()) 
        
        # assess oos preds
        oos_assess = models_user %>%
                select(username, outcome_type, data, glmnet_results) %>% 
                unnest() %>%
                arrange(.row) %>%
                select(username, yearpublished, outcome_type, game_id, name, outcome, .pred_1) %>% 
                mutate(actual = factor(case_when(outcome == 1 ~ 'yes',
                                                 TRUE ~ 'no'))) %>%
                group_by(outcome_type) %>%
                yardstick::roc_auc(truth = actual,
                                   estimate = .pred_1,
                                   event_level = "second") %>%
                mutate_if(is.numeric, round, 3)
        
        # look at top 50 from oos
        ft_oos = oos_preds %>%
                head(100) %>%
                flextable() %>%
                flextable::autofit() %>%
                bg(., i = ~ actual_own == 1,
                   bg = 'deepskyblue1')
        
        
        # predict off baked test data
        test_preds = models_user %>%
                filter(outcome_type != 'rating') %>%
                select(username, outcome_type, glmnet_fit) %>%
                #select(username, outcome_type, glmnet_fit, xgbTree_fit) %>%
                mutate(glmnet_preds = map(glmnet_fit,
                                          ~ .x %>%
                                                  predict(baked_user_collection$test, type = 'prob') %>%
                                                  rename(glmnet = .pred_1) %>%
                                                  select(glmnet) %>%
                                                  mutate(.row = row_number())))%>%
                # mutate(xgbTree_preds = map(xgbTree_fit,
                #                            ~ .x %>%
                #                              predict(baked_test, type = 'prob') %>%
                #                              rename(xgbTree = .pred_1) %>%
                #                              select(xgbTree) %>%
                #                              mutate(.row = row_number()))) %>%
                select(username, outcome_type, glmnet_preds) %>%
                # select(username, outcome_type, glmnet_preds, xgbTree_preds) %>%
                unnest() %>%
                select(-one_of(".row1")) %>%
                left_join(., baked_user_collection$test %>%
                                  mutate(.row = row_number()),
                          by = ".row") %>%
                mutate(user_variable = paste(outcome_type, username, sep="_"))
        

        
        # table
        ft_preds = test_preds %>%
                filter(yearpublished < 2023) %>%
                select(username, yearpublished, outcome_type, game_id, name, glmnet) %>%
                spread(outcome_type, glmnet) %>%
                arrange(own) %>%
                mutate_if(is.numeric, round, 2) %>%
                group_by(yearpublished) %>%
                slice_max(., 
                          order_by = own,
                          n=25,
                          with_ties = T) %>%
                mutate(game_id = as.character(game_id),
                       yearpublished = as.character(yearpublished)) %>%
                select(username, yearpublished, game_id, name, everything()) %>%
          arrange(yearpublished, desc(own)) %>%
          mutate(rank = row_number()) %>%
          select(username, yearpublished, game_id, name, rank, everything()) %>%
                flextable() %>%
                flextable::autofit() %>%
          bg(., i = ~ yearpublished == paste(as.character(params$end_training_year+1)),
             bg = 'grey90') %>%
                  bg(.,
                     j = c("played", "own"),
                     bg = col_func)
          # bg(., i = ~ yearpublished == '2021',
          #            bg = 'grey80') %>%
          #                             bg(., i = ~ yearpublished == '2022',
          #            bg = 'grey100')
          # 
        
        
        # get list of output
        out = list("username" = username,
                   "baked_data" = baked_user_collection,
                   "models" = models_user,
                   "coefs" = coefs_user,
                   "oos" = oos_preds,
                   "oos_table" = ft_oos,
                   "oos_assessment" = oos_assess,
                   "preds" = test_preds,
                   "preds_table" = ft_preds)
        
        return(out)
        
        
}

```

Fit models and analyze collection for **`r params$username`**.

```{r use function, results = 'hide', echo=F, warning=F, message=F}

#use all in one go
foo = analyse_user(params$username,
                   data = bind_rows(games_datasets$train,
                                    games_datasets$test),
                   year_split = params$end_training_year)

```

## Games in Collection

How many games has the user owned/played in the training set (games prior to `r params$end_training_year`)?

```{r get to know collection, echo=F, warning=F, message=F}

temp_own = paste("own", params$username, sep="_")
temp_own2 = rlang::sym(temp_own)

temp_rating = paste("rating", params$username, sep="_")
temp_rating2 = rlang::sym(temp_rating)

foo$baked$training %>%
        mutate(username = params$username) %>%
        mutate(own = !! temp_own2) %>% 
        mutate(rated = case_when(is.na(!!temp_rating2) ~ 0,
                                 TRUE ~ 1)) %>%
        group_by(username) %>%
        summarize(games_owned = sum(own,na.rm=T),
                  games_played = sum(rated, na.rm=T))

rm(temp_own,
   temp_own2,
   temp_rating,
   temp_rating2)

```

## Coefficients for `r params$username`

Examine coefficients from the trained model.

```{r plot coefficients, echo=F, warning=F, message=F, fig.height=11, fig.width=10}

foo$coefs

```

## Visualizing Predictors for `r params$username`'s Collection

Examine density of most important features for predicting whether user owns a game.

```{r get top predictors, warning=F, message=F, fig.height=10, fig.width=10}

top_predictors = foo$models %>%
  filter(outcome_type == 'own') %>%
  mutate(glmnet_coefs = map(glmnet_fit, ~ .x %>% extract_fit_parsnip() %>%
                                                  tidy())) %>%
  select(username, outcome_type, glmnet_coefs) %>%
  unnest() %>%
  mutate(abs = abs(estimate)) %>%
  filter(term != '(Intercept)') %>%
  slice_max(., order_by = abs,
            n = 16,
            with_ties = F) %>%
  pull(term)


source("functions/rename_func.R")

top_predictors_levels = rename_func(top_predictors)


 predictor_plot = foo$models %>%
  filter(outcome_type == 'own') %>%
  select(username, outcome_type, data) %>%
  unnest() %>%
  mutate(outcome = case_when(outcome == 0 ~ 'no',
                                  TRUE ~ 'yes')) %>%
  select(username,
         outcome_type,
         outcome,
         game_id,
         name,
         yearpublished,
         one_of(top_predictors)) %>%
  melt(id.vars = c("username",
                   "outcome_type",
                   "outcome",
                   "game_id",
                   "name",
                   "yearpublished")) %>%
  mutate(variable = factor(rename_func(variable),
                           levels = top_predictors_levels)) %>%
#  mutate(variable = rename_func(variable)) %>%
  ggplot(., aes(x=value,
                fill= outcome,
                color = outcome,
                y=outcome))+
  geom_density_ridges(alpha=0.6)+
  facet_wrap(variable~.,
             scales="free")+
  theme_phil()+
  scale_fill_manual(values = c("grey60", 
                               "deepskyblue1"))+
  scale_color_manual(values = c("grey60", 
                               "deepskyblue1"))+
  guides(fill = "none",
         color = "none")+
    ylab("User Owns Game?")+
    xlab("")+
   labs(title = "What Explains a User's Collection?",
                             subtitle = str_wrap(paste("Plotting density of games owned by user by top predictors from model. Data from all games published before", params$end_training_year), 90))+
   theme(panel.grid.major=element_blank(),
         panel.grid.minor = element_blank())+
   my_caption
 
suppressWarnings({
suppressMessages({
 print(predictor_plot)
})
})

```


## Assessment

Examine separation plot for training set (cross validated predictions).

```{r separation plot for training set, echo=F, warning=F, message=F, fig.height=6, fig.width=10}

foo$oos %>%
        arrange(pred_own) %>%
        mutate(rank = row_number()) %>%
        ggplot(., aes(x=rank,
                      y=pred_own))+
        geom_vline(data = foo$oos %>%
                          arrange(pred_own) %>%
                          mutate(rank = row_number()) %>%
                          filter(actual_own == 1),
                   aes(xintercept = rank),
                  col='deepskyblue1')+
        geom_point(alpha=0.75,size=0.5)+
        facet_wrap(username~.)+
        theme_phil()+
        xlab("Game Rank (Lowest to Highest)")+
        ylab("Pr(Game in Collection)")+
        labs(title = paste("Separation Plot"),
             subtitle = str_wrap("Displaying cross validated probabilities for all games in the training set from least likely to most likely. Vertical blue lines indicate game was actually in the user's collection.", 125))+
        my_caption

```

Formally assess how well the model did in resampling.

```{r assess models in oos, echo=F, warning=F, message=F}

foo$oos_assessment %>%
  flextable() %>%
  flextable::autofit()

```

## Predicted Games in Collection from Training

Examine top games from resampling.

```{r top games from oos, echo=F, warning=F, message=F}

foo$oos_table %>%
  set_caption("Top Overall Games for User from Resampling")

```

### Most and Least Likely Games

What game does the model think `r params$username` is **most likely to own** that is **not** in their collection?

```{r not in collection but likely to own, warning=F, message=F}

foo$oos %>%
  filter(actual_own !=1) %>%
  slice_max(., order_by = pred_own, n=1, with_ties = F) %>%
  select(username, yearpublished, game_id, name, pred_own) %>%
  mutate(pred_own = round(pred_own, 3)) %>%
  flextable()

```

What game does the model think `r params$username` is **least likely to own** that **is** in their collection?

```{r in collection least likely to own, warning=F, message=F}

foo$oos %>%
  filter(actual_own ==1) %>%
  slice_min(., order_by = pred_own, n=1, with_ties = F) %>%
  select(username, yearpublished, game_id, name, pred_own) %>%
  flextable()

```


### Top Games by Year

Top 25 games most likely to be owned by the user in each year, highlighting in blue the games that the user has owned/played.

```{r top games from oos by year, echo=F, warning=F, message=F}

# # games owned
# games_owned = foo$baked_data$training %>%
#   bind_rows(., 
#             foo$baked_data$test) %>%
#   select(yearpublished, game_id, name, contains("own_")) %>%
#   melt(., id.vars = c("yearpublished", "game_id", "name")) %>%
#   filter(value == 1) %>%
#   pull(name) %>%
#   unique()

# games played
games_played = foo$baked_data$training %>%
  bind_rows(., 
            foo$baked_data$test) %>%
  select(yearpublished, game_id, name, contains("played_")) %>%
  melt(., id.vars = c("yearpublished", "game_id", "name")) %>%
  filter(value == 1) %>%
  pull(name) %>%
  unique()

# get top 10 games by year
# year_table = foo$preds %>%
#   filter(yearpublished < 2023) %>%
#                 select(username, yearpublished, outcome_type, game_id, name, glmnet) %>%
#                 spread(outcome_type, glmnet) %>%
#                 arrange(own) %>%
#                 mutate_if(is.numeric, round, 2) %>%
#                 group_by(yearpublished) %>%
#                 mutate(game_id = as.character(game_id),
#                        yearpublished = as.character(yearpublished)) %>%
#                 select(username, yearpublished, game_id, name, everything()) %>%
#           arrange(yearpublished, desc(own)) %>%
#           mutate(rank = row_number()) %>%
#           select(username, yearpublished, game_id, name, rank, everything()) %>%
#   rename(pred_own = own,
#          pred_played = played) %>%
 # bind_rows(foo$oos
year_table = foo$oos %>%
  filter(yearpublished > (params$end_training_year-9)) %>%
  group_by(yearpublished) %>%
  slice_max(., order_by = pred_own, n=25, with_ties = F) %>%
  select(username, yearpublished, name) %>%
  pivot_wider(., id_cols = "username",
              names_from = c("yearpublished"),
              values_from = c("name")) %>%
  unnest() %>%
  select(-username) %>%
  mutate(rank = row_number()) %>%
  select(rank, everything())

# get column names
year_names = names(year_table[,-1])

# get col funcs
bg_picker <- scales::col_factor(
    palette = "deepskyblue1",
    na.color = "white",
    ordered=F,
    levels = games_played)

# display table with colors
year_table %>%
  flextable() %>%
  flextable::autofit() %>%
  bg(., j = year_names,
     bg = bg_picker) %>%
  fontsize(size = 9, part = "all")

  
# foo$oos %>%
#   filter(yearpublished > (params$end_training_year-5)) %>%
#   group_by(yearpublished) %>%
#   slice_max(., order_by = pred_own, n=15) %>%
#   mutate(year_rank = row_number()) %>%
#   arrange(yearpublished, desc(pred_own)) %>%
#   #mutate(yearpublished = as.numeric(yearpublished)) %>%
#   select(username, yearpublished, year_rank, game_id, name, everything()) %>%
#   flextable() %>%
#   flextable::autofit() %>%
#   # bg(., i = ~ (as.numeric(yearpublished) %% 2 == 1),
#   #    bg = 'grey90') %>%
#   # bg(., j = c("pred_played", "pred_own"),
#   #    bg = col_func) %>%
#     bg(., i = ~ actual_own == 1,
#      bg = 'deepskyblue1') %>%
#   set_caption(paste("Top Games for User from Training By Year, ", params$end_training_year-5, "-", params$end_training_year-1, sep=""))

```


### Interactive Table

Interactive table for predictions from resampling.

```{r interactie table for oos preds, warning=F, messagge=F}

foo$oos %>%
  mutate(rank = row_number()) %>%
  arrange(yearpublished, desc(pred_own)) %>%
  #mutate(yearpublished = as.numeric(yearpublished)) %>%
  select(username, yearpublished, rank, game_id, name, everything()) %>%
  DT::datatable()

```

## Predicted Games in Collection `r paste(params$end_training_year, " and On", sep="")`

Examine the top games for the test set.

```{r top games from preds, echo=F, warning=F, message=F}

foo$preds_table %>%
  set_caption(paste("Top Predicted Games for User, ", params$end_training_year, " and On", sep=""))

```

Interactive table for `r paste(params$end_training_year, " and On", sep="")`

```{r interactive preds, echo=F, warning=F, message=F}

foo$preds %>%
                filter(yearpublished < 2023) %>%
                filter(game_id != 295374) %>% # long shot effect
                select(username, yearpublished, outcome_type, game_id, name, glmnet) %>%
                spread(outcome_type, glmnet) %>%
                arrange(own) %>%
                mutate_if(is.numeric, round, 2) %>%
                mutate(game_id = as.character(game_id),
                       yearpublished = as.character(yearpublished)) %>%
                select(username, yearpublished, game_id, name, everything()) %>%
          arrange(desc(own)) %>%
  ungroup() %>%
          mutate(rank = row_number()) %>%
          select(username, yearpublished, game_id, name, rank, everything()) %>%
  DT::datatable()

```
